# Analysis of Paper 506

### Task 1: Extract Key Metadata

- **Title:** An Empirical Study of Code Simplification Methods in Code Intelligence Tasks
- **Authors:** Zongwen Shen, et al.
- **Publication Year:** 2025【4:16†source】

### Task 2: Summarize the Paper

The paper titled "An Empirical Study of Code Simplification Methods in Code Intelligence Tasks" investigates the impact of code simplification techniques on various code intelligence tasks, such as code clone detection, code-to-code search, and code completion. The study employs pre-trained models like CodeBERT and GraphCodeBERT, applying simplification methods to assess their effects on model performance. The authors utilize datasets including BigCloneBench and CodeNet, evaluating the models using metrics like F1-score and MAP. The findings suggest that simplification methods can enhance model performance, with DietCode and SlimCode methods showing notable improvements. The study concludes that code simplification is a valuable approach for improving the efficiency and accuracy of code intelligence models【4:18†source】【4:19†source】.

### Task 3: Extract Dataset Usage

The paper uses the BigCloneBench dataset for the clone detection task and the CodeNet dataset for the code-based code search task【4:0†source】【4:2†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is an empirical study focusing on code simplification methods rather than a literature review or survey.
  - **Quote:** "An Empirical Study of Code Simplification Methods in Code Intelligence Tasks"【4:16†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Evaluate existing approaches.
  - **Explanation:** The paper evaluates the impact of code simplification on existing pre-trained models for clone detection.
  - **Quote:** "We use the BigCloneBench dataset [37] and apply simplification to each code pair to observe the effects"【4:6†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench as a dataset for evaluating clone detection tasks.
  - **Quote:** "We use the BigCloneBench dataset [37] and apply simplification to each code pair to observe the effects"【4:6†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The dataset is used for evaluation, not for training.
  - **Quote:** "We use the BigCloneBench dataset [37] and apply simplification to each code pair to observe the effects"【4:6†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Old version.
  - **Explanation:** The paper mentions using a dataset with over 6,000,000 true clone pairs across 10 functions, which corresponds to the old version.
  - **Quote:** "BigCloneBench is a widely used large-scale code cloning benchmark with over 6,000,000 true clone pairs and 260,000 false clone pairs across 10 functions"【4:6†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, filtered.
  - **Explanation:** The dataset was filtered to remove code snippets without labeled true or false clone pairs.
  - **Quote:** "Specifically, we filtered out code snippets without any labeled true or false clone pairs"【4:6†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not specified.
  - **Explanation:** The paper does not explicitly mention the exclusion of WT3/T4 subsets.
  - **Quote:** Not available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes beyond filtering.
  - **Quote:** Not available.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper follows the settings in CodeXGlue, which implies using a subset defined by previous work.
  - **Quote:** "We processed this dataset following the settings in CodeXGlue [20]"【4:6†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of manual validation or investigation of the dataset's ground truth.
  - **Quote:** Not available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not available.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially weakens.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could affect the validity of the clone detection results if these subsets were included in the evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** If the WT3/T4 subsets were included, the methodology's reliability might be compromised, leading to less accurate conclusions. The generalizability of the findings could be questioned, as the dataset's integrity is crucial for evaluating clone detection performance. However, since the paper does not specify the exclusion of WT3/T4, the exact impact remains uncertain.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 506, No, Evaluate, Yes, No, Old, Yes, Not specified, No, Yes, No, No, Potentially
```

**Note:**
- **B:** The paper evaluates existing approaches rather than presenting a novel one.
- **G:** The paper does not specify whether the WT3/T4 subset was excluded.
- **L:** The finding potentially weakens the paper's claims if the WT3/T4 subset was included in the evaluation.
