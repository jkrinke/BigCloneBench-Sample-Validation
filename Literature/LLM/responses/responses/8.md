# Analysis of Paper 8

### Task 1: Extract Key Metadata

- **Title:** Experiments on Code Clone Detection and Machine Learning
- **Authors:** André Schäfer, Wolfram Amme, Thomas S. Heinze
- **Publication Year:** 2022【4:2†source】.

### Task 2: Summarize the Paper

The paper titled "Experiments on Code Clone Detection and Machine Learning" by André Schäfer, Wolfram Amme, and Thomas S. Heinze explores the application of machine learning techniques to code clone detection. The authors train a graph matching network (GMN) using dominator trees derived from Java bytecode, specifically utilizing the BigCloneBench dataset. The study aims to reproduce previous results and assess the practical relevance of these results by employing a rigorous separation of training and evaluation datasets. Key findings indicate that previous results may lack practical relevance due to insufficient separation of datasets and the absence of a comprehensive ground truth for non-clones. The paper concludes that while machine learning models show promise, the evaluation methodologies and datasets need refinement for more meaningful assessments【4:2†source】【4:4†source】.

### Task 3: Extract Dataset Usage

The paper uses the BigCloneBench dataset for evaluation, specifically focusing on its application in training and evaluating machine learning models for code clone detection. The study also references the CDLH subset of BigCloneBench, which was used in previous works【4:5†source】【4:12†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is an empirical study focusing on experiments with machine learning models for code clone detection.
  - **Quote:** "In this paper, a machine learning model is trained with dominator trees generated from the bytecode of the BigCloneBench benchmark"【4:2†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it evaluates existing approaches.
  - **Explanation:** The paper evaluates the performance of a graph matching network (GMN) on the BigCloneBench dataset.
  - **Quote:** "In this paper, we also focus on machine learning and train a graph matching network (GMN) on dominator trees"【4:4†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench as the primary dataset for evaluating the machine learning model.
  - **Quote:** "The state-of-the-art benchmark for Java is BigCloneBench"【4:4†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench to train the machine learning model.
  - **Quote:** "In this paper, a machine learning model is trained with dominator trees generated from the bytecode of the BigCloneBench benchmark"【4:2†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The paper mentions using the version with 8.5 million hand-checked code clones.
  - **Quote:** "The state-of-the-art benchmark for Java is BigCloneBench, which contains 55,499 Java source code files with 8.5 million hand-checked code clones"【4:4†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it has been filtered.
  - **Explanation:** The paper uses a subset of BigCloneBench after applying the Stubber tool.
  - **Quote:** "The Stubber tool can compile over 95% of all Java source code files in this manner. Thereby, 92.5%, i.e., more than 7.9 million of the originally 8.5 million manually validated clone pairs are preserved"【4:12†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not explicitly mentioned.
  - **Explanation:** The paper does not provide specific details about the exclusion of WT3/T4 subsets.
  - **Quote:** Not available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes or extensions to the ground truth beyond filtering.
  - **Quote:** Not available.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper references the CDLH subset created by Wei and Li.
  - **Quote:** "Wei and Li were the first to create a special subset from BigCloneBench for machine learning tools"【4:5†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any manual validation of BigCloneBench’s ground truth.
  - **Quote:** Not available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not available.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could significantly impact the validity of the paper's results, especially if these pairs were included in the evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology may be flawed if it relied on inaccurate ground truth, leading to potentially misleading conclusions. The generalizability of the results is compromised if the dataset used for training and evaluation contains a high proportion of non-clones, as it would affect the model's ability to generalize to real-world scenarios. The paper's conclusions about the effectiveness of machine learning models for clone detection may need to be revisited in light of this new finding.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 8, No, Yes, Yes, Yes, New, Yes, Not specified, No, Yes, No, No, Yes
```

**Note:**
- **G:** The paper does not specify whether the WT3/T4 subset was excluded from evaluation.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones potentially weakens the paper's claims if these pairs were included in the evaluation.
