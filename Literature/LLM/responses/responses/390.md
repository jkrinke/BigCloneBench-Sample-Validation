# Analysis of Paper 390

### Task 1: Extract Key Metadata

- **Title:** Tool Support for Code Change Inspection with Deep Learning in Evolving Software
- **Authors:** Krishna Teja Ayinala, Kwok Sun Cheng, Kwangsung Oh, Myoungkyu Song
- **Publication Year:** 2020【4:5†source】.

### Task 2: Summarize the Paper

The paper introduces a tool named SIL (Similar Changes Inspection with Deep Learning) designed to assist in code reviews by identifying and summarizing similar code changes. The methodology involves training a deep learning classifier on a clone database to detect similar changes and anomalies in code. The tool is implemented as an Eclipse plug-in and evaluated through a user study with computer science students, who reported positive feedback on its utility in simplifying code review tasks. The study concludes that SIL effectively aids in identifying similar changes and suggests future enhancements for broader applicability【4:5†source】【4:10†source】.

### Task 3: Extract Dataset Usage

The paper uses a clone database mined from 25,000 open-source programs to train the deep learning classifier. This database is used to classify clones into four types based on their similarity【4:5†source】【4:10†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a tool and its evaluation rather than reviewing existing literature systematically.
  - **Quote:** "In this paper, we propose a technique for inspecting similar changes with deep learning"【4:10†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper presents a novel approach named SIL for detecting similar code changes using deep learning.
  - **Quote:** "To address the problem, we propose our approach, Similar Changes Inspection with Deep Learning (SIL)"【4:5†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** No.
  - **Explanation:** The paper does not mention using BigCloneBench; it uses a clone database from 25,000 programs.
  - **Quote:** "In our approach we first train a deep learning classifier, with the clone database, which has around 25000 open source programs"【4:5†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses a different clone database for training.
  - **Quote:** "In our approach we first train a deep learning classifier, with the clone database, which has around 25000 open source programs"【4:5†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Not applicable.
  - **Explanation:** The paper does not use BigCloneBench.
  - **Quote:** N/A

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Not applicable.
  - **Explanation:** The paper does not use BigCloneBench.
  - **Quote:** N/A

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not applicable.
  - **Explanation:** The paper does not use BigCloneBench.
  - **Quote:** N/A

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** Not applicable.
  - **Explanation:** The paper does not use BigCloneBench.
  - **Quote:** N/A

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper uses a clone database created from 25,000 programs, not a subset from previous work.
  - **Quote:** "In our approach we first train a deep learning classifier, with the clone database, which has around 25000 open source programs"【4:5†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not use or validate BigCloneBench.
  - **Quote:** N/A

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** N/A

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** No.
  - **Explanation:** The paper does not use BigCloneBench, so the finding about WT3/T4 pairs does not impact its claims.
  - **Quote:** N/A

The methodology, conclusions, and generalizability of the paper are not affected by the recent findings regarding BigCloneBench, as the paper relies on a different dataset for its evaluations【4:5†source】.

# Summary

Here is the tabular assessment based on the findings:

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 390, No, Yes, No, No, N/A, N/A, N/A, N/A, No, No, No, No
```

**Note:**  
- The paper does not use BigCloneBench, so questions related to its usage (C, D, E, F, G, H, J, K) are marked as "No" or "N/A" as applicable.
- The paper presents a novel approach (B) and does not rely on subsets from previous work (I).
