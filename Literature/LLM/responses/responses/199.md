# Analysis of Paper 199

### Task 1: Extract Key Metadata

- **Title:** Tritor: Detecting Semantic Code Clones by Building Social Network-Based Triads Model
- **Authors:** Deqing Zou, Siyue Feng, Yueming Wu, Wenqi Suo, and Hai Jin
- **Publication Year:** 2023【4:11†source】.

### Task 2: Summarize the Paper

The paper presents a novel system called Tritor for scalable semantic code clone detection. The authors address the challenges of handling complex abstract syntax trees (ASTs) and the lack of semantic information in traditional methods. They propose a triads model that treats the enhanced AST as a social network to capture semantic relationships. The system uses machine learning to classify code clones based on these relationships. Tritor is evaluated against nine state-of-the-art clone detection systems using the Google Code Jam and BigCloneBench datasets, demonstrating superior performance and scalability【4:0†source】【4:4†source】.

### Task 3: Extract Dataset Usage

The paper uses two datasets for evaluation: Google Code Jam (GCJ) and BigCloneBench (BCB)【4:0†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel system for code clone detection rather than reviewing existing literature.
  - **Quote:** "In this paper, we implement a novel system for scalable semantic code clone detection"【4:4†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces Tritor, a new system for semantic code clone detection.
  - **Quote:** "We implement a prototype system namely Tritor"【4:0†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is one of the datasets used for evaluating Tritor.
  - **Quote:** "We implement a prototype system namely Tritor and conduct comparative experiments... on two widely used datasets, Google Code Jam (GCJ) and BigCloneBench (BCB)"【4:0†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench to train a machine learning classifier for code clone detection.
  - **Quote:** "These vectors will be used to train a machine learning classifier for code clone detection"【4:4†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The paper mentions using over eight million clone pairs, which corresponds to the new version.
  - **Quote:** "The second dataset is the popular large code clone benchmark BCB dataset, which contains over eight million labeled clone pairs"【4:10†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it has been filtered.
  - **Explanation:** The paper mentions selecting a subset of 270,000 clone pairs from the dataset.
  - **Quote:** "We randomly select 270,000 clone pairs from the eight million clone pairs"【4:10†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No, it was included.
  - **Explanation:** The paper includes WT3/T4 in the selected subset.
  - **Quote:** "The clone pairs we select include... 109,914 clone pairs of WT3/T4"【4:10†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** There is no indication of changes beyond filtering.
  - **Quote:** Not explicitly mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The subset was created by the authors for this study.
  - **Quote:** "We randomly select 270,000 clone pairs"【4:10†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of manual validation of the ground truth.
  - **Quote:** Not explicitly mentioned.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not found in the references【4:16†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes, it potentially weakens the claims.
  - **Explanation:** The inclusion of WT3/T4 pairs, which are largely not clones, could affect the validity of the evaluation results.
  - **Impact:** The methodology and conclusions regarding the effectiveness of Tritor in detecting semantic clones may be compromised due to the high false positive rate in the WT3/T4 subset. This affects the generalizability of the results, as the dataset's reliability is questioned【4:10†source】.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 199, No, Yes, Yes, Yes, New, Yes, No, No, No, No, No, Potentially
```

**Note:**  
- **F:** The paper filtered the dataset to a subset of 270,000 clone pairs.
- **G:** The WT3/T4 subset was included in the evaluation.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones potentially weakens the paper's claims due to the inclusion of these pairs in the evaluation.
