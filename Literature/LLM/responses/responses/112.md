# Analysis of Paper 112

### Task 1: Extract Key Metadata

- **Title:** An Empirical Study of Parameter-Efficient Fine-Tuning Methods for Pre-Trained Code Models
- **Authors:** Jiaxing Liu, Chaofeng Sha, Xin Peng
- **Publication Year:** 2023【4:5†112_10.1109_ASE56229.2023.00125.pdf】

### Task 2: Summarize the Paper

The paper investigates the effectiveness of parameter-efficient fine-tuning (PEFT) methods on pre-trained code models for various software engineering tasks, including code understanding and generation. The study compares PEFT methods like Adapter and LoRA against full fine-tuning, focusing on their performance in low-resource, cross-language, and cross-project scenarios. The results indicate that PEFT methods can achieve comparable or superior performance to full fine-tuning while significantly reducing computational costs. The study concludes that PEFT methods enhance the transfer learning capabilities of pre-trained models, making them more efficient for practical applications【4:5†112_10.1109_ASE56229.2023.00125.pdf】.

### Task 3: Extract Dataset Usage

The paper uses several datasets for evaluation, including BigCloneBench for code clone detection, Devign for defect detection, CodeSearchNet for code summarization, and a dataset from CodeXGLUE for code translation【4:0†112_10.1109_ASE56229.2023.00125.pdf】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is an empirical study focusing on evaluating fine-tuning methods.
  - **Quote:** "To this end, we first conduct experiments by fine-tuning state-of-the-art code models with these methods on both code understanding tasks and code generation tasks."【4:5†112_10.1109_ASE56229.2023.00125.pdf】

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Evaluate existing approaches.
  - **Explanation:** The paper evaluates existing parameter-efficient fine-tuning methods on pre-trained models.
  - **Quote:** "We experimentally conduct a comprehensive and fair comparison of multiple PEFT methods on code understanding and code generation tasks."【4:13†112_10.1109_ASE56229.2023.00125.pdf】

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as a benchmark for evaluating code clone detection.
  - **Quote:** "We adopt a well-known benchmark for evaluating code clone detection, BigCloneBench."【4:16†112_10.1109_ASE56229.2023.00125.pdf】

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "We adopt a well-known benchmark for evaluating code clone detection, BigCloneBench."【4:16†112_10.1109_ASE56229.2023.00125.pdf】

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Not specified.
  - **Explanation:** The paper does not specify which version of BigCloneBench is used.
  - **Quote:** "We adopt a well-known benchmark for evaluating code clone detection, BigCloneBench."【4:16†112_10.1109_ASE56229.2023.00125.pdf】

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes.
  - **Explanation:** The paper mentions using a subset of BigCloneBench for low-resource scenarios.
  - **Quote:** "To simulate low-resource scenarios, following Wang et al. [12], we randomly sample datasets of 100, 200, 500, and 1,000 samples for defect detection."【4:2†112_10.1109_ASE56229.2023.00125.pdf】

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention the WT3/T4 subset specifically.
  - **Quote:** Not available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench as a benchmark without modifications.
  - **Quote:** "We adopt a well-known benchmark for evaluating code clone detection, BigCloneBench."【4:16†112_10.1109_ASE56229.2023.00125.pdf】

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper follows previous work by Wang et al. for sampling datasets.
  - **Quote:** "To simulate low-resource scenarios, following Wang et al. [12], we randomly sample datasets."【4:2†112_10.1109_ASE56229.2023.00125.pdf】

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any validation or manual investigation of BigCloneBench’s ground truth.
  - **Quote:** Not available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not available.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the evaluation results if these pairs were included in the subset used for evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** If the WT3/T4 subset was included, the evaluation results might be skewed, affecting the reliability of the conclusions regarding the effectiveness of PEFT methods. The generalizability of the findings could be compromised if the dataset's integrity is questioned. However, without specific information on the inclusion of WT3/T4, the exact impact remains uncertain.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 112, No, Yes, Yes, No, Not specified, Yes, Not specified, No, Yes, No, No, Potentially
```

**Note:**  
- **E:** The paper does not specify which version of BigCloneBench is used.
- **G:** The paper does not mention the WT3/T4 subset specifically.
- **L:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could potentially impact the validity of the paper's results if these pairs were included in the evaluation subset. However, without specific information on the inclusion of WT3/T4, the exact impact remains uncertain.
