# Analysis of Paper 248

### Task 1: Extract Key Metadata

- **Title:** Are our clone detectors good enough? An empirical study of code effects by obfuscation
- **Authors:** Weihao Huang, Guozhu Meng, Chaoyang Lin, Qiucun Yan, Kai Chen, Zhuo Ma
- **Publication Year:** 2023【4:0†source】.

### Task 2: Summarize the Paper

The paper titled "Are our clone detectors good enough? An empirical study of code effects by obfuscation" investigates the robustness of clone detection tools, particularly deep learning-based ones, against code obfuscation. The study evaluates nine clone detectors, including both traditional and deep learning-based tools, using a dataset derived from BigCloneBench. The authors obfuscate code pairs using 69 strategies from six commercial obfuscators, generating a benchmark of 524,148 code pairs. The study finds that obfuscation significantly impacts clone detection performance, with deep learning-based detectors being more prone to misclassification. The paper concludes with insights into the effects of obfuscation and provides suggestions for improving clone detection【4:0†source】【4:5†source】【4:8†source】.

### Task 3: Extract Dataset Usage

The paper uses the BigCloneBench dataset for evaluation, specifically collecting 6,512 clone pairs and 1,424 non-clone pairs. These pairs are subjected to obfuscation to create a benchmark for evaluating clone detectors【4:6†source】【4:5†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is an empirical study evaluating clone detection tools against obfuscation, not a literature review or survey.
  - **Quote:** "In this work, we carefully study the status quo of clone detectors, select representative, state-of-art open-source detectors..."【4:16†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Evaluate existing approaches.
  - **Explanation:** The paper evaluates existing clone detection tools against obfuscation.
  - **Quote:** "We conduct a comprehensive study evaluating 3 popular deep-learning based clone detectors and 6 commonly used traditional ones"【4:0†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench to collect clone and non-clone pairs for evaluation.
  - **Quote:** "We collect 6512 clone pairs of five types from the dataset BigCloneBench"【4:0†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The dataset is used for training deep learning models like ASTNN, DeepSim, and CCLearner.
  - **Quote:** "We uniformly utilize the same dataset containing 58,521 clone pairs collected from BigCloneBench for training ASTNN, DeepSim, and CCLearner"【4:14†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Not explicitly stated.
  - **Explanation:** The paper does not specify which version of BigCloneBench is used.
  - **Quote:** Not available.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes.
  - **Explanation:** The dataset is filtered to 6,512 clone pairs and 1,424 non-clone pairs.
  - **Quote:** "We collect 7,936 code pairs from BigCloneBench, which consist of 6,512 clone pairs and 1,424 non-clone pairs"【4:6†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not explicitly stated.
  - **Explanation:** The paper does not mention the exclusion of WT3/T4 subsets.
  - **Quote:** Not available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** Yes.
  - **Explanation:** The dataset is extended with obfuscation strategies to create a larger benchmark.
  - **Quote:** "We obtain 428,695 clone pairs and 95,453 non-clone pairs after obfuscation"【4:5†source】.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper creates its own subset from BigCloneBench.
  - **Quote:** "We collect 7,936 code pairs from BigCloneBench"【4:6†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any manual validation of BigCloneBench’s ground truth.
  - **Quote:** Not available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not available.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could affect the validity of the paper's results if these pairs were included in the evaluation.
  - **Impact:** This could affect the methodology and conclusions, particularly if the WT3/T4 pairs were used in the evaluation, leading to inaccurate assessments of clone detection performance. The generalizability of the findings might be compromised if the dataset's integrity is questioned.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 248, No, Evaluate existing approaches, Yes, Yes, Not specified, Yes, Not specified, Yes, No, No, No, Potentially
```

**Note:**  
- **E:** The paper does not specify which version of BigCloneBench is used.
- **G:** The paper does not mention the exclusion of the WT3/T4 subset.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones could potentially affect the paper's results if these pairs were included in the evaluation.
