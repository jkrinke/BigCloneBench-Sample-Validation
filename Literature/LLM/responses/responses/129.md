# Analysis of Paper 129

### Task 1: Extract Key Metadata

- **Title:** Contrastive Learning of Functionality-Aware Code Embeddings
- **Authors:** Yiyang Li, Hongqiu Wu, Hai Zhao
- **Publication Year:** 2023【4:10†source】

### Task 2: Summarize the Paper

The paper presents a novel approach called Functionality-aware Code Embeddings (FaCE) that leverages contrastive learning to improve code comprehension. The authors aim to address the limitations of pre-trained language models on code by focusing on the functionality of code snippets rather than their semantic meaning. They construct positive and hard negative samples based on code functionality and pre-train their model using a contrastive learning framework. The study evaluates FaCE on two benchmarks, including code clone detection using BigCloneBench, demonstrating its effectiveness and robustness compared to existing models【4:10†source】【4:14†source】.

### Task 3: Extract Dataset Usage

The paper uses two benchmark datasets for evaluation: BigCloneBench for code clone detection and CodeSearchNet for natural language code search【4:0†source】【4:2†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature.
  - **Quote:** "In this paper, we present Functionality-aware Code Embeddings (FaCE)..."【4:10†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces FaCE, a new method for code comprehension.
  - **Quote:** "In this paper, we propose FaCE, a novel pre-trained language model..."【4:14†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used for evaluating code clone detection.
  - **Quote:** "We conduct our experiments on two benchmark datasets, BigCloneBench..."【4:0†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench for training in few-shot scenarios.
  - **Quote:** "For few-shot scenario, we train each model on code clone detection task using only 0.01%, 0.05%, 0.1%, 0.3%, 0.5% and 1% of the training set of BigCloneBench..."【4:15†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** The version is not explicitly mentioned.
  - **Explanation:** The paper does not specify which version of BigCloneBench is used.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it has been filtered for few-shot learning.
  - **Explanation:** The paper mentions using a small percentage of the dataset for training.
  - **Quote:** "using only 0.01%, 0.05%, 0.1%, 0.3%, 0.5% and 1% of the training set of BigCloneBench..."【4:15†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention the WT3/T4 subset specifically.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not indicate any changes to the ground truth beyond filtering for few-shot learning.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention using a subset from previous work.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of validation or manual investigation of BigCloneBench’s ground truth.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially, yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the results if these pairs were included in the evaluation or training subsets. However, the paper does not specify the use of WT3/T4, so the direct impact is unclear.

- **Impact on Methodology, Conclusions, or Generalizability:**
  - The methodology might be affected if the WT3/T4 subset was used, as it could introduce noise into the training or evaluation process. This could lead to overestimated performance metrics. The conclusions regarding the effectiveness of FaCE might need reevaluation if the dataset's integrity is compromised by such non-clone pairs. The generalizability of the findings could be questioned if the dataset's ground truth is unreliable.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 129, No, Yes, Yes, Yes, Not specified, Yes, Not specified, No, Not specified, No, No, Potentially
```

**Note:**
- **E:** The version of BigCloneBench used is not specified in the paper.
- **G:** The paper does not mention the WT3/T4 subset specifically.
- **I:** There is no indication that a subset from previous work was used.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones could potentially impact the paper's claims if these pairs were included, but this is not specified.
