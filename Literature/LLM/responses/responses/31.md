# Analysis of Paper 31

### Task 1: Extract Key Metadata

- **Title:** Goner: Building Tree-Based N-Gram-Like Model for Semantic Code Clone Detection
- **Authors:** Yueming Wu, Siyue Feng, Wenqi Suo, Deqing Zou, and Hai Jin
- **Publication Year:** 2023【4:2†source】.

### Task 2: Summarize the Paper

The paper introduces a novel tree-based code clone detection method named Goner, which aims to efficiently detect semantic code clones at a large scale. The methodology involves transforming complex tree structures into simpler N-gram-like subtrees, which are then used to train a machine learning model for clone detection. The study evaluates Goner using the BigCloneBench and Google Code Jam datasets, demonstrating superior performance in accuracy and speed compared to ten state-of-the-art clone detection tools. The paper concludes that Goner is highly effective in detecting semantic clones and offers significant scalability improvements【4:1†source】【4:2†source】.

### Task 3: Extract Dataset Usage

The paper uses two prominent datasets for evaluation: BigCloneBench (BCB) and Google Code Jam (GCJ)【4:1†source】【4:13†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature.
  - **Quote:** "The focus of this article is to propose a novel and scalable tree-based code clone detector"【4:1†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces Goner, a new tree-based code clone detection method.
  - **Quote:** "We propose a novel tree-based scalable semantic code clone detection method"【4:2†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is one of the datasets used for evaluating Goner.
  - **Quote:** "We have developed a prototype system, namely, Goner and extensively evaluate the system using two prominent datasets: BigCloneBench (BCB) and Google Code Jam (GCJ)"【4:1†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The dataset is used to train the machine learning model for clone detection.
  - **Quote:** "We train a machine learning model for semantic code clone detection"【4:2†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The paper mentions using a dataset with more than eight million labeled clone pairs.
  - **Quote:** "It contains more than eight million labeled clone pairs"【4:15†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it has been filtered.
  - **Explanation:** A subset of 270,000 clone pairs was selected for analysis.
  - **Quote:** "For the BCB dataset, we randomly select 270,000 clone pairs from the extensive pool of eight million clone pairs"【4:15†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No, it was included.
  - **Explanation:** The WT3/T4 subset is part of the selected clone pairs.
  - **Quote:** "The clone pairs we selected include... 109,914 clone pairs of Weakly Type-3/Type-4 (WT3/T4)"【4:15†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** There is no indication of changes beyond filtering.
  - **Quote:** Not explicitly mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The subset was randomly selected by the authors.
  - **Quote:** "We randomly select 270,000 clone pairs"【4:15†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of manual validation of the ground truth.
  - **Quote:** Not explicitly mentioned.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not found in the references【4:4†source】【4:5†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes, it potentially weakens the claims.
  - **Explanation:** The paper reports high effectiveness in detecting WT3/T4 clones, which are now known to be largely non-clones.
  - **Quote:** "Goner attains a remarkable F1 score of 96%... in detecting WT3/T4"【4:14†source】.

- **Impact on Methodology, Conclusions, or Generalizability:**
  - The finding that 93.35% of WT3/T4 pairs are not clones suggests that the high F1 score reported for WT3/T4 detection may be misleading. This could affect the perceived accuracy and reliability of Goner's results, particularly in detecting semantic clones. The methodology may need to be revisited to ensure that the evaluation metrics accurately reflect the tool's performance. The generalizability of the conclusions regarding Goner's effectiveness in detecting semantic clones is also impacted, as the dataset's integrity is compromised.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 31, No, Yes, Yes, Yes, New, Yes, No, No, No, No, No, Potentially
```

**Note:**
- **F:** The ground truth of BigCloneBench was filtered to a subset of 270,000 clone pairs.
- **G:** The WT3/T4 subset was included in the evaluation.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones potentially weakens the claims regarding the effectiveness of the tool in detecting these types of clones.
