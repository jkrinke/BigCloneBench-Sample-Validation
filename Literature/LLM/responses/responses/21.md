# Analysis of Paper 21

### Task 1: Extract Key Metadata

- **Title:** FaCoY – A Code-to-Code Search Engine
- **Authors:** Kisub Kim, Dongsun Kim, Tegawendé F. Bissyandé, Eunjong Choi, Li Li, Jacques Klein, Yves Le Traon
- **Publication Year:** 2018【4:18†source】

### Task 2: Summarize the Paper

The paper introduces FaCoY, a novel static code-to-code search engine designed to find semantically similar code fragments in large code bases. The approach leverages query alternation and structuring to improve search results, moving beyond mere syntactic pattern detection. FaCoY is evaluated using the BigCloneBench benchmark, demonstrating superior performance in identifying semantic clones compared to existing tools. The study concludes that FaCoY is effective for code search and patch recommendation, with potential applications in software transplantation and repair【4:0†source】【4:18†source】.

### Task 3: Extract Dataset Usage

The paper uses the BigCloneBench dataset for evaluation, specifically a recent snapshot that includes clone pairs clustered in 43 functionality groups【4:4†source】【4:15†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature.
  - **Quote:** "We propose FaCoY (Find a Code other than Yours) as a novel, static, scalable and effective code-to-code search engine"【4:0†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper introduces FaCoY, a new code-to-code search engine.
  - **Quote:** "We propose FaCoY (Find a Code other than Yours) as a novel, static, scalable and effective code-to-code search engine"【4:0†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench to evaluate the performance of FaCoY.
  - **Quote:** "We further show, with the BigCloneBench benchmark, that we perform better than the state-of-the-art on static code clone detectors identifying semantic clones"【4:0†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training a machine learning model.
  - **Quote:** "We present evaluation results demonstrating that FaCoY can accurately help search for (syntactically and semantically) similar code fragments"【4:0†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The paper uses a snapshot of BigCloneBench with 43 functionality groups.
  - **Quote:** "We use a recent snapshot of BigCloneBench including clone pairs clustered in 43 functionality groups"【4:4†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes.
  - **Explanation:** The paper considers clone pairs with at least 6 lines and 50 tokens.
  - **Quote:** "We consider 8,345,104 clone pairs in BigCloneBench based on the same criteria used in [74]: both code fragments in a clone pair have at least 6 lines and 50 tokens in length"【4:4†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No.
  - **Explanation:** WT3/T4 is included in the evaluation.
  - **Quote:** "While most tools detect little to no WT3/T4 code clone pairs, FaCoY is able to find over 635,000 clones in the IJADataset"【4:14†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes or extensions to the ground truth.
  - **Quote:** Not explicitly mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper uses criteria from previous work for selecting clone pairs.
  - **Quote:** "We consider 8,345,104 clone pairs in BigCloneBench based on the same criteria used in [74]"【4:4†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** Yes.
  - **Explanation:** The paper manually verifies some false positives.
  - **Quote:** "We manually verify the clone pairs that are not associated in BigCloneBench, but FaCoY recommended as code clones"【4:19†source】.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not mentioned in the references【4:1†source】【4:6†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could significantly impact the validity of FaCoY's results, especially since the paper highlights its ability to detect WT3/T4 clones.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology relying on WT3/T4 pairs as ground truth is compromised, potentially affecting the conclusions about FaCoY's effectiveness in detecting semantic clones. The generalizability of the results is also affected, as the dataset's reliability is questioned【4:14†source】【4:19†source】.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 21, No, Yes, Yes, No, New, Yes, No, No, Yes, Yes, No, Yes
```

**Note:**  
- **F:** The paper filters the dataset to include clone pairs with at least 6 lines and 50 tokens.
- **G:** WT3/T4 subset is included in the evaluation.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones potentially weakens the paper's claims regarding FaCoY's effectiveness in detecting semantic clones.
