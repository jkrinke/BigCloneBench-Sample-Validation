# Analysis of Paper 28

### Task 1: Extract Key Metadata

- **Title:** Review Sharing via Deep Semi-Supervised Code Clone Detection
- **Authors:** Chenkai Guo, Hui Yang, Dengrong Huang, Jianwen Zhang, Naipeng Dong, Jing Xu, Jingwen Zhu
- **Publication Year:** 2020【4:1†source】.

### Task 2: Summarize the Paper

The paper presents a novel approach to improve code quality by sharing code reviews between projects with sufficient reviews and those with few reviews. It introduces a deep learning-based code clone detection model using a semi-supervised Convolutional Neural Network (CNN) to identify similar code fragments across projects. The methodology involves transforming code and reviews into numerical vectors, training a model on BigCloneBench and real code-review pairs, and employing heuristic filtering and LDA-based ranking for review presentation. The study concludes that the proposed RSharer+ system effectively enhances clone detection precision and facilitates meaningful review sharing【4:1†source】【4:11†source】.

### Task 3: Extract Dataset Usage

The paper uses the BigCloneBench dataset for evaluating the clone detection model. It also utilizes real code-review pairs from code management platforms for training and testing【4:1†source】【4:8†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is not a systematic literature review or a survey; it presents a novel approach for code clone detection and review sharing.
  - **Quote:** "In this paper, we try to address the problem via building a review sharing channel..."【4:1†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper presents a novel clone detection approach using a semi-supervised CNN model.
  - **Quote:** "We introduce a novel code clone detection model based on Convolutional Neural Network (CNN)..."【4:1†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used for training and evaluating the clone detection model.
  - **Quote:** "The collected datasets are first transformed into context-sensitive numerical vectors in the data preprocessing. Then in the clone detection, data vectors are trained and tested on the BigCloneBench..."【4:1†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as part of the training data for the semi-supervised CNN model.
  - **Quote:** "The autoencoder-based semi-supervised CNN model is proposed to alleviate the dataset heterogeneity, which is trained on the BigCloneBench..."【4:11†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Old version.
  - **Explanation:** The paper mentions using BigCloneBench covering 10 functionalities, which corresponds to the old version.
  - **Quote:** "The labelled dataset is constructed by the code pairs from popular clone dataset BigCloneBench, which covers 10 functionalities."【4:8†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes.
  - **Explanation:** The paper uses a subset of 98.4k labelled clone pairs from BigCloneBench.
  - **Quote:** "The overall clone detection result for 98.4k labelled clone pairs in BigCloneBench is shown..."【4:15†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No.
  - **Explanation:** The WT3/T4 subset is included in the evaluation.
  - **Quote:** "The true clone pairs are labelled with 6 different tags: T1 (Type 1), T2 (Type 2), VST3 (Very Strong Type 3), ST3 (Strong Type 3), MT3 (Moderately Type 3), and WT3/4 (Weak Type 3 or Type 4), respectively."【4:8†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes, extensions, or enrichment to the ground truth beyond filtering.
  - **Quote:** Not explicitly mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper does not mention using a subset created by previous work.
  - **Quote:** Not explicitly mentioned.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any validation or manual investigation of BigCloneBench’s ground truth.
  - **Quote:** Not explicitly mentioned.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not found in the references【4:0†source】【4:6†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could significantly impact the validity of the paper's results, as these pairs are included in the evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology relies on the accuracy of BigCloneBench as a ground truth dataset. If a large portion of the dataset is incorrect, it could lead to misleading conclusions about the effectiveness of the clone detection model. The generalizability of the results is also affected, as the model's performance may not be as robust as reported if tested against a more accurate dataset.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 28, No, Yes, Yes, Yes, Old, Yes, No, No, No, No, No, Yes
```

**Note:**  
- **F:** The paper uses a subset of 98.4k labelled clone pairs from BigCloneBench.
- **G:** The WT3/T4 subset is included in the evaluation.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones could weaken the paper's claims.
