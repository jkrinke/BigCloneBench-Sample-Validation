# Analysis of Paper 84

### Task 1: Extract Key Metadata

- **Title:** The title of the paper is not explicitly mentioned in the snippets provided, but it is associated with the DOI 10.1109/ASE56229.2023.00149.
- **Authors:** The authors are not explicitly listed in the snippets provided.
- **Publication Year:** 2023【4:9†source】.

### Task 2: Summarize the Paper

The paper presents CODA, a novel technique for generating adversarial examples to test and enhance the robustness of deep code models. CODA focuses on reducing the ingredient space for adversarial example generation by utilizing code differences between reference inputs and the target input. The study evaluates CODA across five code-based tasks, demonstrating its effectiveness in revealing more faults with less time compared to state-of-the-art techniques like CARROT and ALERT. The results indicate that CODA significantly improves model robustness without compromising performance【4:8†source】【4:17†source】.

### Task 3: Extract Dataset Usage

The paper uses several datasets for evaluation, including BigCloneBench for the task of clone detection. Other datasets mentioned include those for vulnerability prediction, authorship attribution, functionality classification, and defect prediction【4:0†source】【4:2†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is not a systematic literature review or a survey; it presents a novel technique for adversarial example generation.
  - **Quote:** "To improve test effectiveness on deep code models, we propose a novel perspective by exploiting the code differences..."【4:8†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper presents a novel approach, CODA, for generating adversarial examples to test deep code models.
  - **Quote:** "We propose a novel perspective by exploiting the code differences between reference inputs and the target input to guide the generation of adversarial examples"【4:8†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as a dataset for the clone detection task.
  - **Quote:** "Its used dataset is from BigCloneBench [43], the most widely-used dataset for clone detection"【4:2†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "Its used dataset is from BigCloneBench [43], the most widely-used dataset for clone detection"【4:2†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** The version is not specified.
  - **Explanation:** The paper does not specify which version of BigCloneBench is used.
  - **Quote:** "Its used dataset is from BigCloneBench [43], the most widely-used dataset for clone detection"【4:2†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Not specified.
  - **Explanation:** The paper does not provide details on filtering or modifying BigCloneBench.
  - **Quote:** Not available.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention the exclusion of the WT3/T4 subset.
  - **Quote:** Not available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention any changes, extensions, or enrichment to the ground truth.
  - **Quote:** Not available.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention using a subset created by previous work.
  - **Quote:** Not available.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of validation or manual investigation of BigCloneBench’s ground truth.
  - **Quote:** Not available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not available.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** If the WT3/T4 subset is included in the evaluation and contains a high percentage of non-clones, it could affect the validity of the clone detection results.
  - **Impact:** The methodology and conclusions regarding the effectiveness of CODA in clone detection could be compromised if the dataset used contains significant inaccuracies. This would affect the generalizability of the findings, particularly in the context of clone detection tasks.

# Summary

```csv
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 84, No, Yes, Yes, No, Not specified, Not specified, Not specified, Not specified, Not specified, No, No, Potentially
```

**Note:**  
- The paper does not specify which version of BigCloneBench is used, nor does it provide details on filtering, modifying, or using subsets of the dataset. 
- The potential impact of the WT3/T4 subset's inaccuracies on the paper's findings is noted, as it could affect the validity of the clone detection results if included.
