# Analysis of Paper 47

### Task 1: Extract Key Metadata

- **Title:** CCAligner: A Token Based Large-Gap Clone Detector
- **Authors:** Pengcheng Wang, Jeffrey Svajlenko, Yanzhao Wu, Yun Xu, Chanchal K. Roy
- **Publication Year:** 2018【4:1†source】.

### Task 2: Summarize the Paper

The paper introduces CCAligner, a novel tool designed to detect large-gap clones, which are complex Type-3 clones with significant edits. The authors propose a token-based approach using code windows and an e-mismatch index to improve detection accuracy. The methodology involves evaluating CCAligner against state-of-the-art tools like NiCad and SourcererCC using empirical studies and a mutation-injection framework. The key findings demonstrate that CCAligner outperforms existing tools in detecting large-gap clones and maintains competitive performance for general Type-1, Type-2, and Type-3 clone detection. The paper concludes that CCAligner is effective for large-gap clone detection and scalable for large codebases【4:1†source】【4:5†source】.

### Task 3: Extract Dataset Usage

The paper uses BigCloneBench for evaluation, specifically employing the BigCloneEval framework to conduct custom recall measurement experiments【4:13†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel tool and evaluates it, rather than reviewing existing literature.
  - **Quote:** "In this paper, we propose a tool, CCAligner, using code window that considers e edit distance for matching to detect large-gap clones"【4:1†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper introduces CCAligner, a new tool for detecting large-gap clones.
  - **Quote:** "In this paper, we propose a tool, CCAligner, using code window that considers e edit distance for matching to detect large-gap clones"【4:1†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench to evaluate the performance of CCAligner.
  - **Quote:** "We try various combinations of q, e to evaluate CCAligner with BigCloneBench using the BigCloneEval framework"【4:13†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training a machine learning model.
  - **Quote:** "We try various combinations of q, e to evaluate CCAligner with BigCloneBench using the BigCloneEval framework"【4:13†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The paper refers to BigCloneBench as having a large number of manually validated clones, which aligns with the new version.
  - **Quote:** "BigCloneBench is a large benchmark of manually validated clones in a large inter-project Java repository"【4:13†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** No specific filtering or modification mentioned.
  - **Explanation:** The paper does not mention any filtering or modification of BigCloneBench.
  - **Quote:** "We try various combinations of q, e to evaluate CCAligner with BigCloneBench using the BigCloneEval framework"【4:13†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not mentioned.
  - **Explanation:** The paper does not specify the exclusion of WT3/T4 subsets.
  - **Quote:** Not available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench as provided without changes.
  - **Quote:** "BigCloneBench is a large benchmark of manually validated clones"【4:13†source】.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench directly without mentioning subsets from previous work.
  - **Quote:** Not available.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any validation or manual investigation of BigCloneBench’s ground truth.
  - **Quote:** Not available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not available.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of evaluations using these pairs as ground truth. If CCAligner’s performance was measured using these pairs, the results might be skewed.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology might need revision to exclude or re-evaluate the WT3/T4 pairs. The conclusions regarding CCAligner’s effectiveness could be affected if these pairs were a significant part of the evaluation. The generalizability of the results might be limited if the evaluation relied heavily on these incorrect pairs.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 47, No, Yes, Yes, No, New, No, Not specified, No, No, No, No, Potentially
```

**Note:**  
- For question G, the paper does not specify whether the WT3/T4 subset was excluded from evaluation.
- For question L, the finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could potentially weaken the paper's claims if these pairs were used in the evaluation.
