# Analysis of Paper 97

### Task 1: Extract Key Metadata

- **Title:** Low-Complexity Code Clone Detection using Graph-based Neural Networks
- **Authors:** Hu Liu, Hui Zhao, Changhao Han, Lu Hou
- **Publication Year:** 2022【4:5†source】

### Task 2: Summarize the Paper

The paper proposes a low-complexity code clone detection method using graph-based neural networks. The approach involves preprocessing code into abstract syntax trees (ASTs) and then converting them into graphs with reduced redundancy by pruning unnecessary edges. The model employs a combination of graph neural networks and gated recurrent units (GRU) to efficiently learn and detect code clones. The experimental results demonstrate that the proposed method reduces computational complexity and training time while maintaining performance comparable to existing methods. The authors conclude that their approach is suitable for large datasets and can be extended to various programming languages【4:5†source】【4:6†source】.

### Task 3: Extract Dataset Usage

The paper uses two datasets for evaluation: BigCloneBench (BCB) and Google Code Jam (GCJ). The BCB dataset is used as a real-world benchmark platform, and the GCJ dataset is used to test the model's performance on a different type of dataset【4:18†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature systematically.
  - **Quote:** "In this paper, we propose a low-complex code clone detection with the graph-based neural network." (Page 1)【4:5†source】

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces a new method for code clone detection using graph-based neural networks.
  - **Quote:** "This paper proposes a low-complex code clone detection with the graph-based neural network." (Page 1)【4:5†source】

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The BCB dataset is explicitly mentioned as being used for evaluation.
  - **Quote:** "The original dataset used in this paper are BigCloneBench (BCB) and Google Code Jam (GCJ)." (Page 8)【4:18†source】

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The BCB dataset is used as a benchmark for evaluating the proposed model.
  - **Quote:** "The BCB dataset is a real-world benchmark platform for using manually validated clones." (Page 8)【4:18†source】

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Old version.
  - **Explanation:** The paper mentions 10 functional types, which corresponds to the old version of BCB.
  - **Quote:** "It covers 10 functional types, including 8,584,153 positive clone pairs." (Page 8)【4:18†source】

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it has been filtered.
  - **Explanation:** The paper describes a cleaned version of the BCB dataset.
  - **Quote:** "The number of code pairs in the cleaned BCB dataset." (Page 8)【4:18†source】

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No, it was included.
  - **Explanation:** The WT3/T4 subset is part of the evaluation.
  - **Quote:** "WT3/T4 Total False 0 0 19 213 149768 150000 True 20000 3000 20000 50000 157000 250000" (Page 8)【4:18†source】

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes beyond filtering.
  - **Quote:** Not explicitly mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper describes its own filtering process.
  - **Quote:** "The number of code pairs in the cleaned BCB dataset." (Page 8)【4:18†source】

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of manual validation of the BCB ground truth.
  - **Quote:** Not explicitly mentioned.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not found in the references【4:1†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes, it potentially weakens the claims.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs are not clones suggests that the evaluation results using this subset may be unreliable.
  - **Impact:** This affects the methodology and conclusions, as the reliability of the results is compromised. The generalizability of the findings is also affected, as the dataset's integrity is in question. The paper's claims about the model's performance on the BCB dataset may need reevaluation considering this new information.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 97, No, Yes, Yes, Yes, Old, Yes, No, No, No, No, No, Potentially
```

**Note:**  
- **F:** The paper mentions a "cleaned" version of the BCB dataset, indicating filtering.
- **G:** The WT3/T4 subset was included in the evaluation.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones potentially weakens the paper's claims, affecting the reliability of the results.
