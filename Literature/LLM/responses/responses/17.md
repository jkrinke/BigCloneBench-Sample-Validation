# Analysis of Paper 17

### Task 1: Extract Key Metadata

- **Title:** SourcererCC: Scaling Code Clone Detection to Big-Code
- **Authors:** Hitesh Sajnani, Vaibhav Saini, Jeffrey Svajlenko, Chanchal K. Roy, Cristina V. Lopes
- **Publication Year:** 2016【4:5†source】.

### Task 2: Summarize the Paper

The paper presents SourcererCC, a token-based clone detector designed to efficiently detect both exact and near-miss clones in large inter-project repositories using a standard workstation. The methodology involves using an optimized inverted-index and filtering heuristics to reduce the number of code-block comparisons. The study evaluates SourcererCC's scalability, execution time, recall, and precision against four state-of-the-art tools using benchmarks like BigCloneBench and a Mutation/Injection-based framework. The findings indicate that SourcererCC achieves high recall and precision, demonstrating its capability to scale to large codebases and effectively detect Type-3 clones【4:5†source】【4:14†source】.

### Task 3: Extract Dataset Usage

The paper uses two datasets for evaluation: BigCloneBench, a benchmark of real clones, and a Mutation/Injection-based framework for fine-grained artificial clones【4:5†source】【4:14†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel tool and evaluates it, rather than reviewing existing literature.
  - **Quote:** "In this paper, we present a token-based clone detector, SourcererCC..."【4:5†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces SourcererCC, a new clone detection tool.
  - **Quote:** "In this paper, we present a token-based clone detector, SourcererCC..."【4:5†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used to measure recall.
  - **Quote:** "We measure its clone recall using two proven clone benchmarks. We use BigCloneBench..."【4:14†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "We measure its clone recall using two proven clone benchmarks. We use BigCloneBench..."【4:14†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** The paper does not specify the version.
  - **Explanation:** The paper refers to BigCloneBench generally without specifying the version.
  - **Quote:** "We use BigCloneBench, a big benchmark of real clones..."【4:14†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it was filtered.
  - **Explanation:** The paper mentions using a reduction of IJaDataset containing known true and false clones from BigCloneBench.
  - **Quote:** "We avoid the scalability issue by executing the tools for a reduction of IJaDataset with only those files containing the known true and false clones in BigCloneBench..."【4:9†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Yes, WT3/T4 was excluded.
  - **Explanation:** The paper states that WT3/T4 clones are outside the scope of the study.
  - **Quote:** "SourcererCC has poor recall for the MT3 and WT3/T4, which is expected as these clones fall outside the range of syntactical clone detectors."【4:9†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes to the ground truth beyond filtering.
  - **Quote:** Not explicitly mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper uses a reduction of IJaDataset based on known clones from BigCloneBench.
  - **Quote:** "We avoid the scalability issue by executing the tools for a reduction of IJaDataset with only those files containing the known true and false clones in BigCloneBench..."【4:9†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any manual validation of BigCloneBench’s ground truth.
  - **Quote:** Not explicitly mentioned.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not found in the references【4:0†source】【4:13†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes, it potentially weakens the claims.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones suggests that the recall results for these types of clones may be unreliable. Since the paper reports poor recall for WT3/T4, this finding aligns with the paper's results but also questions the reliability of the benchmark for these clone types.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology relying on BigCloneBench for recall measurement may be affected, particularly for WT3/T4 clones. The conclusions regarding the tool's performance on these clone types may need reevaluation, and the generalizability of the results could be limited if the benchmark's accuracy is compromised.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 17, No, Yes, Yes, No, Not specified, Yes, Yes, No, Yes, No, No, Potentially
```

**Note:**  
- **E:** The version of BigCloneBench used is not specified in the paper.
- **L:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones potentially weakens the claims regarding the tool's performance on these clone types.
