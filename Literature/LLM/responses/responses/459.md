# Analysis of Paper 459

### Task 1: Extract Key Metadata

- **Title:** Scalable code clone detection and search based on adaptive prefix filtering
- **Authors:** Manziba Akanda Nishi, Kostadin Damevski
- **Publication Year:** 2018【4:5†source】

### Task 2: Summarize the Paper

The paper presents a novel code clone detection technique utilizing adaptive prefix filtering to improve scalability and performance over existing methods like SourcererCC. The authors aim to enhance execution time and maintain high precision and recall across large-scale code repositories. The methodology involves a two-step process of filtering and verification to efficiently detect Type-1, Type-2, and Type-3 clones. Experimental results demonstrate significant improvements in execution time and candidate filtering, with the technique being applicable to both code clone detection and search. The study concludes with suggestions for future work to extend the technique's applicability【4:5†source】【4:18†source】.

### Task 3: Extract Dataset Usage

The paper uses the IJaDataset 2.0, a large code clone benchmark containing 250MLOC and 25,000 open source Java systems, for evaluating their proposed code clone detection tool【4:18†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel technique rather than reviewing existing literature.
  - **Quote:** "In this paper, we described a novel code clone detection technique utilizing the adaptive prefix filtering heuristic"【4:18†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces a new technique for code clone detection and search.
  - **Quote:** "A novel code clone detection technique that can scale to very large scale source code repositories"【4:19†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench as part of its evaluation framework.
  - **Quote:** "Measurement of clone recall and precision has been greatly aided by recent datasets and frameworks like BigCloneEval (2017). This framework can be used for the evaluation of code clone detection tools based on the BigCloneBench clone detection benchmark"【4:17†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper does not mention using BigCloneBench for training machine learning models.
  - **Quote:** Not applicable.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** The paper does not specify the version.
  - **Explanation:** The paper references BigCloneBench but does not specify which version is used.
  - **Quote:** "BigCloneBench contains a large set of known clones from the inter-project software repository IJaDataset 2.0"【4:17†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** No specific filtering or modification is mentioned.
  - **Explanation:** The paper does not detail any filtering or modification of BigCloneBench.
  - **Quote:** Not applicable.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No exclusion is mentioned.
  - **Explanation:** The paper evaluates recall for WT3/T4 clones.
  - **Quote:** "For measuring recall using BigCloneBench, Type-3 and Type-4 code clones are separated in four categories... Weakly Type-3 (WT3/T4)"【4:17†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes to the ground truth.
  - **Quote:** Not applicable.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper uses the IJaDataset 2.0, which is a known dataset.
  - **Quote:** "We have evaluated our proposed code clone detection tool by randomly creating a subset of the IJaDataset 2.0"【4:18†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any manual validation of BigCloneBench.
  - **Quote:** Not applicable.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not applicable.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially, yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could affect the paper's recall evaluation, particularly for Type-3 and Type-4 clones.
  - **Impact on Methodology:** The methodology relying on BigCloneBench for recall measurement might be compromised if the dataset's accuracy is in question.
  - **Impact on Conclusions:** The conclusions regarding the effectiveness of the technique for detecting Type-3 and Type-4 clones may need reevaluation.
  - **Impact on Generalizability:** The generalizability of the results could be limited if the dataset used for evaluation is flawed.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 459, No, Yes, Yes, No, Not specified, No, No, No, Yes, No, No, Potentially
```

**Note:**  
- **E:** The paper does not specify which version of BigCloneBench is used.
- **L:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could potentially weaken the paper's claims regarding recall evaluation for Type-3 and Type-4 clones.
