# Analysis of Paper 145

### Task 1: Extract Key Metadata

- **Title:** Finding repeated strings in code repositories and its applications to code-clone detection
- **Authors:** Yoriyuki Yamagata, Fabien Hervé, Yuji Fujiwara, Katsuro Inoue
- **Publication Year:** 2021【4:5†source】

### Task 2: Summarize the Paper

The paper proposes a lightweight, language-independent method for detecting code clones by identifying repeated strings in code repositories, termed as weak Type-1 clones. This approach, implemented in a tool called CodeRepeat, avoids the complexities of lexing and parsing, making it easier to deploy across different programming languages. The study evaluates CodeRepeat using BigCloneEval on BigCloneBench, demonstrating its effectiveness in detecting Type-1 and some Type-2 clones. The paper concludes that CodeRepeat is fast, memory-efficient, and robust in real-world settings, although it does not measure precision and has limitations in handling certain configurations【4:5†source】【4:6†source】【4:7†source】.

### Task 3: Extract Dataset Usage

The paper uses BigCloneBench for evaluation, specifically employing BigCloneEval to measure recall rates of different types of clones【4:1†source】【4:8†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel method for clone detection rather than reviewing existing literature.
  - **Quote:** "This paper proposes a lightweight language-independent method to detect code clones by simply finding repeated strings in a code repository"【4:5†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces CodeRepeat, a new method for detecting code clones.
  - **Quote:** "This paper proposes a lightweight language-independent method to detect code clones by simply finding repeated strings in a code repository"【4:5†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench to evaluate the recall rates of different types of clones.
  - **Quote:** "We performed the benchmark using BigCloneEval, which measures recall rates of different types of clones in BigCloneBench"【4:1†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper does not involve machine learning; it focuses on a string-matching approach.
  - **Quote:** "Our method always outputs exact matches and does not use any approximation, heuristics, or machine-learning based method"【4:9†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** The paper does not specify the version.
  - **Explanation:** The paper mentions using BigCloneBench but does not detail which version.
  - **Quote:** "BigCloneBench provides a well-curated dataset of code clones extracted from open-source Java projects"【4:1†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified?
  - **A:** No indication of filtering or modification.
  - **Explanation:** The paper does not mention any filtering or modification of BigCloneBench.
  - **Quote:** Not explicitly mentioned in the text.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention the exclusion of any subsets.
  - **Quote:** Not explicitly mentioned in the text.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench as provided without changes.
  - **Quote:** Not explicitly mentioned in the text.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench directly without referencing a subset from previous work.
  - **Quote:** Not explicitly mentioned in the text.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any validation or manual investigation of BigCloneBench.
  - **Quote:** Not explicitly mentioned in the text.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not explicitly mentioned in the text.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially, yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the recall rates reported in the paper, especially if these pairs were included in the evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology might be affected if the WT3/T4 subset was used without exclusion, leading to inflated recall rates. This could also affect the generalizability of the conclusions regarding the effectiveness of CodeRepeat in detecting clones. However, since the paper does not specify the exclusion of WT3/T4, the exact impact is uncertain.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 145, No, Yes, Yes, No, Not specified, No, Not specified, No, No, No, No, Potentially
```

**Note:**  
- **E:** The paper does not specify which version of BigCloneBench was used.
- **G:** The paper does not mention the exclusion of the WT3/T4 subset.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones could potentially weaken the paper's claims if these pairs were included in the evaluation.
