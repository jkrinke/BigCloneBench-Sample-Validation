# Analysis of Paper 366

### Task 1: Extract Key Metadata

- **Title:** FastDCF: A Partial Index Based Distributed and Scalable Near-Miss Code Clone Detection Approach for Very Large Code Repositories
- **Authors:** Liming Yang, Yi Ren, Jianbo Guan, Bao Li, Jun Ma, Peng Han, Yusong Tan
- **Publication Year:** 2022【4:5†source】

### Task 2: Summarize the Paper

The paper presents FastDCF, a distributed and scalable near-miss code clone detection tool designed for large code repositories. The objective is to improve clone detection efficiency and scalability using a partial index-based approach combined with distributed parallelization. The methodology involves using MapReduce and HDFS to overcome single-node resource limitations, allowing FastDCF to detect Type-1, Type-2, and Type-3 clones across multiple programming languages and code granularities. Key findings indicate that FastDCF achieves high recall and precision, outperforming existing tools in execution time and scalability. The paper concludes that FastDCF is a competitive tool for large-scale clone detection, with future plans to apply it to vulnerability detection in large software systems【4:5†source】【4:6†source】.

### Task 3: Extract Dataset Usage

The paper uses BigCloneBench as a benchmark to evaluate the recall and precision of FastDCF. It also mentions using IJaDataset for building inputs of different sizes【4:8†source】【4:19†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel tool and evaluates its performance.
  - **Quote:** "In this paper, we present FastDCF, a fast and scalable distributed clone finder..."【4:5†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces FastDCF, a new tool for clone detection.
  - **Quote:** "In this paper, we present FastDCF, a fast and scalable distributed clone finder..."【4:5†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used to measure recall and precision.
  - **Quote:** "We measure FastDCF’s recall BigCloneBench [27], and we also measure the precision."【4:8†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "We measure FastDCF’s recall BigCloneBench [27], and we also measure the precision."【4:8†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** The paper does not specify the version.
  - **Explanation:** The paper refers to BigCloneBench generally without specifying the version.
  - **Quote:** "BigCloneBench is a big clone benchmark of manually validated clone pairs..."【4:7†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified?
  - **A:** Yes.
  - **Explanation:** The paper excludes certain types of clones from consideration.
  - **Quote:** "MT3 and WT3/4 are not belong to near miss clones, therefore they are not in consideration of our work."【4:7†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation?
  - **A:** Yes.
  - **Explanation:** The paper explicitly states that WT3/T4 are not considered.
  - **Quote:** "MT3 and WT3/4 are not belong to near miss clones, therefore they are not in consideration of our work."【4:7†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes beyond filtering.
  - **Quote:** Not applicable.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper does not mention using a subset from previous work.
  - **Quote:** Not applicable.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any manual validation of BigCloneBench.
  - **Quote:** Not applicable.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not applicable.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes.
  - **Explanation:** The exclusion of WT3/T4 subsets, which are found to be largely incorrect, suggests that the paper's results may be more reliable than if these subsets were included. However, the paper's reliance on BigCloneBench for evaluation means that any inaccuracies in the dataset could still affect the validity of the results.
  - **Quote:** "MT3 and WT3/4 are not belong to near miss clones, therefore they are not in consideration of our work."【4:7†source】.

- **Impact on Methodology, Conclusions, or Generalizability:**
  - The exclusion of WT3/T4 subsets mitigates some concerns about the dataset's accuracy, potentially strengthening the paper's conclusions. However, the generalizability of the results may still be limited by the inherent issues in BigCloneBench, as the paper does not validate the dataset's ground truth. The methodology remains robust due to the exclusion of problematic subsets, but the conclusions should be interpreted with caution regarding the dataset's overall reliability.

# Summary

```csv
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 366, No, Yes, Yes, No, Not specified, Yes, Yes, No, No, No, No, Yes
```

**Note:**  
- The paper does not specify which version of BigCloneBench is used, hence "Not specified" is used for question E.
- The exclusion of WT3/T4 subsets, which are largely incorrect, suggests that the paper's results may be more reliable than if these subsets were included, hence "Yes" for question L.
