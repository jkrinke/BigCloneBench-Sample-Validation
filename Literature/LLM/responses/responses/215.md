# Analysis of Paper 215

### Task 1: Extract Key Metadata

- **Title:** Poison Attack and Poison Detection on Deep Source Code Processing Models
- **Authors:** Jia Li, Zhuo Li, HuangZhao Zhang, Ge Li, Zhi Jin, Xing Hu, and Xin Xia
- **Publication Year:** 2024【4:1†source】

### Task 2: Summarize the Paper

The paper titled "Poison Attack and Poison Detection on Deep Source Code Processing Models" explores the vulnerabilities of deep learning models used in source code processing to poison attacks. The authors propose a novel approach named CodePoisoner for generating poison samples and CodeDetector for detecting them. The study evaluates these methods across three tasks: defect detection, clone detection, and code repair, using datasets like BigCloneBench. The results demonstrate that CodePoisoner effectively conducts poison attacks with high success rates, while CodeDetector successfully identifies poison samples, suggesting the need for improved defense mechanisms in software engineering【4:2†source】【4:12†source】.

### Task 3: Extract Dataset Usage

The paper uses the following datasets for evaluation:
- **Defect Detection:** Devign dataset
- **Clone Detection:** BigCloneBench
- **Code Repair:** Raw Java dataset collected by Tufano et al.【4:12†source】

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is an empirical study focusing on poison attacks and detection in deep learning models for source code processing.
  - **Quote:** "In this article, we conduct experiments on three representative source code processing tasks (i.e., defect detection, clone detection, and code repair)."【4:0†source】

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces CodePoisoner and CodeDetector for poison attack and detection.
  - **Quote:** "To alleviate these problems, we propose a new poison detection approach named CodeDetector."【4:3†source】

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as a benchmark for clone detection.
  - **Quote:** "We experiment with a widely used benchmark named BigCloneBench."【4:12†source】

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "We experiment with a widely used benchmark named BigCloneBench."【4:12†source】

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Not specified.
  - **Explanation:** The paper does not specify which version of BigCloneBench is used.
  - **Quote:** "We experiment with a widely used benchmark named BigCloneBench."【4:12†source】

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention any filtering or modification of BigCloneBench.
  - **Quote:** "We experiment with a widely used benchmark named BigCloneBench."【4:12†source】

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not specified.
  - **Explanation:** The paper does not provide details on the exclusion or inclusion of the WT3/T4 subset.
  - **Quote:** "We experiment with a widely used benchmark named BigCloneBench."【4:12†source】

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention any changes, extensions, or enrichment to the ground truth.
  - **Quote:** "We experiment with a widely used benchmark named BigCloneBench."【4:12†source】

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention using a subset created by previous work.
  - **Quote:** "We experiment with a widely used benchmark named BigCloneBench."【4:12†source】

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of validation or manual investigation of BigCloneBench’s ground truth.
  - **Quote:** "We experiment with a widely used benchmark named BigCloneBench."【4:12†source】

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** The citation list does not include "BigCloneBench Considered Harmful for Machine Learning."【4:0†source】

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially, yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the clone detection results if these pairs were included in the evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** If the WT3/T4 subset was used without filtering, the evaluation results might be skewed, affecting the reliability of the conclusions regarding the effectiveness of CodePoisoner and CodeDetector in clone detection tasks. This could limit the generalizability of the findings to real-world scenarios where accurate clone detection is critical.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 215, No, Yes, Yes, No, Not specified, Not specified, Not specified, Not specified, Not specified, No, No, Potentially
```

**Note:**  
- The paper does not specify which version of BigCloneBench is used, nor does it provide details on filtering, modification, or the use of subsets like WT3/T4.  
- The potential impact of the finding regarding WT3/T4 pairs being non-clones could affect the validity of the paper's results if these pairs were included in the evaluation.
