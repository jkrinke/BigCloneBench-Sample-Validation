# Analysis of Paper 9

### Task 1: Extract Key Metadata

- **Title:** CodeBERT for Code Clone Detection: A Replication Study
- **Authors:** Saad Arshad, Shamsa Abid, Shafay Shamail
- **Publication Year:** 2022【4:1†source】.

### Task 2: Summarize the Paper

The paper titled "CodeBERT for Code Clone Detection: A Replication Study" aims to evaluate the performance of CodeBERT, a pre-trained model, for code clone detection across multiple datasets. The study investigates CodeBERT's ability to generalize to unseen code and the impact of fine-tuning on its performance. The authors use three datasets: a subset of BigCloneBench, SemanticCloneBench, and an Android dataset. Key findings indicate that CodeBERT performs well for Type-1 and Type-4 clones but shows limited generalizability to unseen functionalities. Fine-tuning improves recall significantly on SemanticCloneBench and Android datasets. The study concludes that while CodeBERT is effective for certain clone types, its performance varies across different datasets【4:1†source】【4:3†source】【4:16†source】.

### Task 3: Extract Dataset Usage

The paper uses three datasets for evaluation: a subset of BigCloneBench, SemanticCloneBench, and an Android dataset【4:3†source】【4:11†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is an empirical study focused on evaluating the performance of CodeBERT for code clone detection.
  - **Quote:** "In this paper, we aim to replicate and evaluate the performance of CodeBERT for code clone detection on multiple datasets"【4:1†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Evaluate existing approaches.
  - **Explanation:** The paper evaluates the existing CodeBERT model for code clone detection.
  - **Quote:** "In this paper, we aim to replicate and evaluate the performance of CodeBERT for code clone detection"【4:1†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses a subset of BigCloneBench for evaluation.
  - **Quote:** "We reproduce the code clone detection of CodeBERT on a subset of the BigCloneBench dataset"【4:5†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "We reproduce the code clone detection of CodeBERT on a subset of the BigCloneBench dataset"【4:5†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Old version.
  - **Explanation:** The paper refers to a subset of BigCloneBench, which aligns with the old version's characteristics.
  - **Quote:** "BigCloneBench contains six million true positive clones of different clone types"【4:4†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it has been filtered.
  - **Explanation:** The paper uses a filtered subset called BigCloneBenchsub.
  - **Quote:** "We derive our first evaluation dataset from a filtered version of the BigCloneBench dataset"【4:11†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No, it was included.
  - **Explanation:** The WT3/T4 clone types are part of the evaluation.
  - **Quote:** "We consider strong Type-3 clones (ST3) as having a 70-100% syntactic similarity, moderate Type-3 (MT3) clones having a 50-70% similarity and weak Type-3 or Type-4 (WT3/4) clones having 0-50% similarity"【4:11†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes beyond filtering.
  - **Quote:** "We derive our first evaluation dataset from a filtered version of the BigCloneBench dataset"【4:11†source】.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The subset used is derived from previous work.
  - **Quote:** "The original BigCloneBench dataset contains methods which did not belong to any similar or dissimilar class of method pairs and those methods were filtered out for use in previous clone detection experiments using CodeBERT"【4:11†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any manual validation of BigCloneBench’s ground truth.
  - **Quote:** Not explicitly mentioned in the paper.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not found in the references【4:6†source】【4:15†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could significantly impact the validity of the paper's results, especially since WT3/T4 clones are part of the evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology relying on WT3/T4 clones may be flawed, leading to inaccurate conclusions about CodeBERT's performance. The generalizability of the results is compromised, as the evaluation dataset's integrity is questionable. This could lead to overestimating CodeBERT's effectiveness for detecting certain clone types【4:11†source】【4:18†source】.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 9, No, Yes, Yes, No, Old, Yes, No, No, Yes, No, No, Yes
```

**Note:**  
- **F:** The paper uses a filtered subset of BigCloneBench.
- **G:** WT3/T4 clones are included in the evaluation.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones weakens the paper's claims regarding CodeBERT's performance.
