# Analysis of Paper 119

### Task 1: Extract Key Metadata

- **Title:** Code Clone Detection Based on Contrastive Learning
- **Authors:** Chunli Xie, Yao Liang, Quanrun Lv, Zexuan Wan
- **Publication Year:** 2024【4:11†source】.

### Task 2: Summarize the Paper

The paper proposes a self-supervised learning method for code clone detection using contrastive learning and gated recurrent units (GRU) to extract code features. The objective is to improve code representation learning under small sample conditions, addressing the limitations of existing methods that require large labeled datasets. The methodology involves data augmentation through semantic-preserving transformations and the use of a Siamese network for similarity evaluation. Key findings indicate that the proposed model outperforms state-of-the-art methods by 8% in F1 score on benchmark datasets. The paper concludes that the approach effectively enhances code clone detection efficiency and suggests future work on optimizing code representation and encoder selection【4:11†source】【4:2†source】【4:10†source】.

### Task 3: Extract Dataset Usage

The paper uses BigCloneBench as the primary dataset for evaluating the proposed model. It consists of Java code fragments from 25,000 systems covering 10 functions, including 6,000,000 true clone pairs and 260,000 false clone pairs【4:1†source】【4:6†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is not a systematic literature review or a survey; it presents a novel approach to code clone detection.
  - **Quote:** "In this paper, we propose a self-supervised learning method for code clone detection"【4:2†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces a new self-supervised learning method for code clone detection.
  - **Quote:** "In this paper, we propose a self-supervised learning method for code clone detection"【4:2†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used to evaluate the proposed model.
  - **Quote:** "We choose BigCloneBench, a widely used clone detection by Svajlenko et.al. [24] to evaluate the proposed model"【4:6†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "We choose BigCloneBench... to evaluate the proposed model"【4:6†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Old version.
  - **Explanation:** The description matches the old version with 10 functionalities.
  - **Quote:** "BigCloneBench consists of java code fragments... covering 10 functions"【4:6†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** No indication of filtering or modification.
  - **Explanation:** The paper does not mention any filtering or modification of BigCloneBench.
  - **Quote:** Not explicitly mentioned.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not specified.
  - **Explanation:** The paper does not provide details on the exclusion of WT3/T4 subsets.
  - **Quote:** Not explicitly mentioned.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench as provided without changes.
  - **Quote:** Not explicitly mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper uses the full dataset as described.
  - **Quote:** Not explicitly mentioned.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of validation or manual investigation of the dataset.
  - **Quote:** Not explicitly mentioned.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not found in the references【4:14†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially weakens.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs are not clones could impact the validity of the evaluation results if these pairs were included in the dataset used for evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology and conclusions might be affected if the evaluation relied heavily on these pairs, as it could lead to overestimated performance metrics. The generalizability of the results could be questioned if the dataset's integrity is compromised by such inaccuracies. However, without explicit mention of WT3/T4 usage, the exact impact remains speculative.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 119, No, Yes, Yes, No, Old, No, Not specified, No, No, No, No, Potentially
```

**Note:**  
- **G (WT3/T4 subset):** The paper does not specify whether the WT3/T4 subset was excluded from evaluation.
- **L (Impact of WT3/T4 finding):** The finding potentially weakens the paper's claims if the WT3/T4 pairs were included in the evaluation, as it could affect the accuracy of the results. However, the exact impact is speculative without explicit mention of WT3/T4 usage.
