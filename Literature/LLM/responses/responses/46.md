# Analysis of Paper 46

### Task 1: Extract Key Metadata

- **Title:** InferCode: Self-Supervised Learning of Code Representations by Predicting Subtrees
- **Authors:** Nghi D. Q. Bui, Yijun Yu, Lingxiao Jiang
- **Publication Year:** 2021【4:9†46_10.1109_ICSE43902.2021.00109.pdf】

### Task 2: Summarize the Paper

The paper introduces InferCode, a self-supervised learning model designed to generate code representations by predicting subtrees in abstract syntax trees (ASTs). The objective is to overcome the limitations of existing models that require labeled datasets for specific tasks. InferCode is trained on a large set of Java code using a Tree-Based Convolutional Neural Network (TBCNN) as the encoder. The model is evaluated on several downstream tasks, including code clustering, clone detection, and cross-language code search, demonstrating superior performance compared to existing baselines. The study concludes that InferCode's self-supervised approach can produce transferable models suitable for various code learning tasks【4:9†46_10.1109_ICSE43902.2021.00109.pdf】.

### Task 3: Extract Dataset Usage

The paper uses two datasets for evaluation: the OJ Dataset, which contains 52,000 C/C++ programs, and BigCloneBench, a Java dataset widely used for benchmarking code clone detection techniques【4:2†46_10.1109_ICSE43902.2021.00109.pdf】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature systematically.
  - **Quote:** Not applicable as the paper does not claim to be an SLR or survey.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper introduces InferCode, a novel self-supervised learning approach for code representation.
  - **Quote:** "To overcome the limitation, this paper proposes InferCode, which adapts the self-supervised learning idea from natural language processing to the abstract syntax trees (ASTs) of code"【4:9†46_10.1109_ICSE43902.2021.00109.pdf】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as one of the datasets for evaluating the clone detection task.
  - **Quote:** "The other is the BigCloneBench, a Java dataset that has been widely used to benchmark code clone detection techniques"【4:2†46_10.1109_ICSE43902.2021.00109.pdf】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "We use the well-known Precision, Recall, and F1 scores. Since the task is unsupervised, in this paper we compare InferCode only with unsupervised clone detectors that do not require labeled data"【4:14†46_10.1109_ICSE43902.2021.00109.pdf】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Old version.
  - **Explanation:** The paper mentions 6 million true clone pairs and 260,000 false clone pairs, which corresponds to the old version.
  - **Quote:** "covering 10 functionalities and including 6,000,000 true clone pairs and 260,000 false clone pairs"【4:2†46_10.1109_ICSE43902.2021.00109.pdf】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** No.
  - **Explanation:** The paper does not mention any filtering or modification of BigCloneBench.
  - **Quote:** Not applicable as no filtering is mentioned.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No information provided.
  - **Explanation:** The paper does not specify whether WT3/T4 was excluded or included.
  - **Quote:** Not applicable as the paper does not mention WT3/T4.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench as is for evaluation.
  - **Quote:** Not applicable as no changes are mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper does not mention using a subset from previous work.
  - **Quote:** Not applicable as no subset usage is mentioned.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any validation or manual investigation of BigCloneBench.
  - **Quote:** Not applicable as no validation is mentioned.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not applicable as the citation is not present.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the evaluation results if these pairs were included in the evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** If WT3/T4 pairs were included, the evaluation results might be skewed, affecting the reported performance metrics like precision, recall, and F1 score. This could lead to overestimation of the model's effectiveness, thus affecting the generalizability of the conclusions. However, since the paper does not specify the inclusion of WT3/T4, the exact impact is uncertain.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 46, No, Yes, Yes, No, Old, No, Not specified, No, No, No, No, Potentially
```

**Note:**  
- **G:** The paper does not specify whether the WT3/T4 subset was excluded or included in the evaluation.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones could potentially impact the validity of the paper's results if these pairs were included in the evaluation. However, the paper does not specify the inclusion of WT3/T4, making the exact impact uncertain.
