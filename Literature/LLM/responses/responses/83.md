# Analysis of Paper 83

### Task 1: Extract Key Metadata

- **Title:** CCEyes: An Effective Tool for Code Clone Detection on Large-Scale Open Source Repositories
- **Authors:** Yanzhi Zhang, Tao Wang
- **Publication Year:** 2021【4:2†source】.

### Task 2: Summarize the Paper

The paper presents CCEyes, a tool designed for detecting code clones in large-scale open-source repositories, particularly on GitHub. The tool utilizes deep learning techniques to create semantic vector representations of code, which are stored in a database to enhance detection efficiency. CCEyes employs a Recursive Autoencoder for feature extraction and a Siamese network for similarity evaluation. The study includes comprehensive experiments comparing CCEyes with other tools, demonstrating its superior performance in terms of detection accuracy and efficiency. The authors conclude that CCEyes is a valuable tool for developers, aiding in code maintenance and reuse【4:2†source】【4:6†source】.

### Task 3: Extract Dataset Usage

The paper uses BigCloneBench as a dataset for evaluating the clone detection capabilities of CCEyes. It specifically mentions using tagged clone pairs from BigCloneBench for evaluation【4:12†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is not a systematic literature review or a survey; it presents a tool for clone detection.
  - **Quote:** "In this paper, we propose CCEyes, an effective tool for code clone detection on GitHub"【4:2†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper presents a novel tool, CCEyes, for code clone detection.
  - **Quote:** "In this paper, we propose CCEyes, an effective tool for code clone detection on GitHub"【4:2†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench to evaluate the clone detection capabilities of CCEyes.
  - **Quote:** "We evaluate the algorithmic capabilities of CCEyes to determine true or false clone pairs by detecting tagged clone pairs in BigCloneBench"【4:12†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench for evaluation, not for training.
  - **Quote:** "We evaluate the algorithmic capabilities of CCEyes to determine true or false clone pairs by detecting tagged clone pairs in BigCloneBench"【4:12†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The paper mentions using over 8.8 million true clone pairs, which corresponds to the new version of BigCloneBench.
  - **Quote:** "So we use the remaining 8,854,73 true clone pairs tagged in the table CLONES"【4:12†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes.
  - **Explanation:** The paper mentions filtering out wrongly marked functions and using a subset of the data.
  - **Quote:** "We discard the code fragments without any tagged true or false clone pairs to ensure the accuracy of the experiment. And we removed 25 functions wrongly marked by BigCloneBench"【4:12†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not explicitly mentioned.
  - **Explanation:** The paper does not specify whether the WT3/T4 subset was excluded or included.
  - **Quote:** Not available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes, extensions, or enrichment to the ground truth beyond filtering.
  - **Quote:** Not available.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper does not mention using a subset created by previous work.
  - **Quote:** Not available.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any validation or manual investigation of BigCloneBench’s ground truth.
  - **Quote:** Not available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not available.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the evaluation results if these pairs were included in the evaluation subset.
  - **Impact on Methodology, Conclusions, or Generalizability:** If the WT3/T4 subset was included, the methodology's reliability could be questioned, potentially affecting the conclusions drawn about CCEyes' effectiveness. The generalizability of the results might be compromised if the evaluation relied on incorrect clone pairs. However, without explicit mention of WT3/T4 in the paper, the exact impact remains speculative.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 83, No, Yes, Yes, No, New, Yes, Not specified, No, No, No, No, Potentially
```

**Note:**  
- For question G, the paper does not specify whether the WT3/T4 subset was excluded or included.
- For question L, the impact of the finding regarding WT3/T4 pairs is speculative due to the lack of explicit mention in the paper.
