# Analysis of Paper 37

### Task 1: Extract Key Metadata

- **Title:** Assessing and Improving Dataset and Evaluation Methodology in Deep Learning for Code Clone Detection
- **Authors:** Haiyang Li, Qing Gao, and Shikun Zhang
- **Publication Year:** 2023【4:0†source】.

### Task 2: Summarize the Paper

The paper aims to evaluate and improve the dataset and evaluation methodologies used in deep learning for code clone detection. The authors conduct experiments to assess the performance of state-of-the-art models from multiple perspectives and introduce two new datasets, ConBigCloneBench and GoogleCodeJam2, based on existing datasets like BigCloneBench. Their findings reveal significant performance variations across different evaluation perspectives, suggesting that current models may be overestimated. The study concludes with recommendations for future research to enhance model performance by considering dataset quality and evaluation methodologies【4:0†source】【4:2†source】.

### Task 3: Extract Dataset Usage

The paper uses several datasets for evaluation, including BigCloneBench, GoogleCodeJam, and introduces two new datasets, ConBigCloneBench and GoogleCodeJam2, which are based on the existing datasets【4:2†source】【4:6†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is an empirical study focusing on dataset and evaluation methodology improvements rather than a literature review or survey.
  - **Quote:** "In this paper, we conduct experiments to evaluate the performance of the existing state-of-the-art models in multi-perspectives"【4:0†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Evaluate existing approaches.
  - **Explanation:** The paper evaluates the performance of existing deep learning models for code clone detection.
  - **Quote:** "We conduct experiments from multi-perspectives for state-of-the-art clone detection deep learning models"【4:6†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as a basis for creating the ConBigCloneBench dataset.
  - **Quote:** "We release two new datasets for code clone detection, namely ConBigCloneBench and GoogleCodeJam2 based on the existing datasets BigCloneBench and GoogleCodeJam"【4:0†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper does not mention using BigCloneBench as ground truth for training but rather for evaluation.
  - **Quote:** "We conduct experiments from multi-perspectives for state-of-the-art clone detection models"【4:6†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Not explicitly stated.
  - **Explanation:** The paper does not specify which version of BigCloneBench is used.
  - **Quote:** "BigCloneBench is a code clone detection dataset proposed by Roy et al."【4:3†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, modified.
  - **Explanation:** The paper introduces ConBigCloneBench, which is a modified version of BigCloneBench.
  - **Quote:** "We release two new datasets for code clone detection, ConBigCloneBench and GoogleCodeJam2"【4:6†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not explicitly stated.
  - **Explanation:** The paper does not mention the WT3/T4 subset specifically.
  - **Quote:** Not available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** Yes.
  - **Explanation:** The paper introduces a new dataset, ConBigCloneBench, which suggests changes or extensions to the original dataset.
  - **Quote:** "The new datasets corrected the misuse in previous research work with higher data quality"【4:9†source】.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper builds on existing datasets like BigCloneBench to create new datasets.
  - **Quote:** "We release two new datasets for clone detection, ConBigCloneBench and GoogleCodeJam2 based on BigCloneBench and GoogleCodeJam"【4:6†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any manual validation of BigCloneBench’s ground truth.
  - **Quote:** Not available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** Yes.
  - **Explanation:** The paper cites the work discussing the issues with BigCloneBench.
  - **Quote:** "Jens Krinke et al. pointed out that previous research work had wrong assumption in using BigCloneBench"【4:10†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially weakens.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the dataset used for evaluation, affecting the credibility of the results.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology and conclusions may be affected as the dataset's reliability is questioned. This could lead to a reassessment of the model's performance and generalizability, especially if WT3/T4 pairs were part of the evaluation【4:10†source】.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 37, No, Yes, Yes, No, Not specified, Yes, Not specified, Yes, Yes, No, Yes, Potentially
```

**Note:** 
- For question E, the version of BigCloneBench used is not specified in the paper.
- For question G, the paper does not explicitly mention the WT3/T4 subset.
- For question L, the finding that 93.35% of WT3/T4 pairs are not clones potentially weakens the paper's claims, as it questions the dataset's reliability.
