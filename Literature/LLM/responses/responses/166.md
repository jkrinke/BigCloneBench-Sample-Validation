# Analysis of Paper 166

### Task 1: Extract Key Metadata

- **Title:** TreeCen: Building Tree Graph for Scalable Semantic Code Clone Detection
- **Authors:** Yutao Hu, Deqing Zou, Junru Peng, Yueming Wu, Junjie Shan, and Hai Jin
- **Publication Year:** 2022【4:4†source】.

### Task 2: Summarize the Paper

The paper introduces TreeCen, a novel scalable tree-based semantic code clone detector. The primary objective is to address the high runtime overhead of existing tree-based approaches by transforming complex abstract syntax trees (ASTs) into simpler graph representations, termed tree graphs. These graphs are analyzed using social network-based centrality measures to produce fixed-length vectors, which are then used to train a machine learning model for clone detection. The study evaluates TreeCen's performance on the Google Code Jam and BigCloneBench datasets, demonstrating superior detection accuracy and scalability compared to six state-of-the-art methods【4:0†source】【4:3†source】.

### Task 3: Extract Dataset Usage

The paper uses two datasets for evaluation: Google Code Jam (GCJ) and BigCloneBench (BCB)【4:0†source】【4:8†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature systematically.
  - **Quote:** "In this paper, we propose TreeCen, a scalable tree-based semantic code clone detector"【4:4†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces TreeCen, a new method for scalable semantic code clone detection.
  - **Quote:** "We propose a novel approach to simplify an AST into a simple graph representation"【4:3†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is one of the datasets used to evaluate TreeCen.
  - **Quote:** "We evaluate TreeCen on two widely used datasets, i.e., Google Code Jam (GCJ) and BigCloneBench (BCB)"【4:16†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench to train the machine learning model for clone detection.
  - **Quote:** "Finally, these vectors are fed into a machine learning model to detect clones"【4:10†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The paper mentions over 8,000,000 tagged clone pairs, which corresponds to the new version.
  - **Quote:** "The BCB dataset composes of over 8,000,000 tagged clone pairs covering all clone types"【4:8†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it has been filtered.
  - **Explanation:** The paper filters out cloned code pairs with less than five code lines.
  - **Quote:** "We filter out the cloned code pairs with less than five code lines. Finally, 270,000 cloned code pairs have remained"【4:8†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No, WT3/T4 was not excluded.
  - **Explanation:** The paper does not mention excluding WT3/T4 specifically.
  - **Quote:** "The BCB dataset...further divides Type-3 clones into Strongly Type-3 (ST3), Moderately Type-3 (MT3), and Weakly Type-3 (WT3)"【4:8†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes beyond filtering.
  - **Quote:** Not explicitly mentioned.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper does not mention using a subset from previous work.
  - **Quote:** Not explicitly mentioned.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any manual validation of BigCloneBench’s ground truth.
  - **Quote:** Not explicitly mentioned.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not found in the references【4:15†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes, it potentially weakens the claims.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could affect the validity of the results, especially if these pairs were used in training or evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology might be compromised if the model was trained on incorrect labels, leading to inaccurate conclusions. The generalizability of the results could be questioned, as the dataset's reliability is crucial for validating the effectiveness of TreeCen.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 166, No, Yes, Yes, Yes, New, Yes, No, No, No, No, No, Potentially
```

**Note:**  
- **F:** The paper filtered the dataset to include only cloned code pairs with at least five lines, resulting in 270,000 pairs.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones potentially weakens the paper's claims, as it could affect the validity of the results if these pairs were used in training or evaluation.
