# Analysis of Paper 200

### Task 1: Extract Key Metadata

- **Title:** NIL: Large-Scale Detection of Large-Variance Clones
- **Authors:** Tasuku Nakagawa, Yoshiki Higo, and Shinji Kusumoto
- **Publication Year:** 2021【4:11†source】.

### Task 2: Summarize the Paper

The paper presents NIL, a scalable clone detection tool designed to identify large-variance clones in large codebases. The authors propose a technique that uses N-grams and an inverted index to efficiently identify clone candidates, followed by verification using the longest common subsequence (LCS) method. NIL is evaluated against existing tools like LVMapper, CCAligner, SourcererCC, and NiCad, demonstrating high precision and recall in large-variance clone detection, as well as superior scalability. The study concludes that NIL is effective for detecting large-variance clones and suggests future research directions in software engineering applications【4:16†source】【4:17†source】.

### Task 3: Extract Dataset Usage

The paper uses two benchmarks for evaluation: the Mutation Framework and BigCloneEval, which utilizes BigCloneBench【4:15†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel tool and its evaluation rather than reviewing existing literature.
  - **Quote:** "In this study, we proposed NIL, which achieves both large-variance clone detection and scalability"【4:4†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper introduces NIL, a new clone detection tool.
  - **Quote:** "In this paper, we propose a scalable clone detection technique that can detect large-variance clones from large codebases and describe its implementation, called NIL"【4:16†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as part of the BigCloneEval benchmark to measure recall and precision.
  - **Quote:** "BigCloneEval [33] automatically measures the recall of clone detectors using BigCloneBench [32]"【4:15†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper does not mention using BigCloneBench for training machine learning models.
  - **Quote:** Not applicable.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** The paper does not specify.
  - **Explanation:** The paper refers to BigCloneBench but does not indicate which version is used.
  - **Quote:** "BigCloneEval [33] automatically measures the recall of clone detectors using BigCloneBench [32]"【4:15†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** No.
  - **Explanation:** The paper does not mention filtering or modifying BigCloneBench.
  - **Quote:** Not applicable.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** The paper does not specify.
  - **Explanation:** There is no mention of excluding or specifically including the WT3/T4 subset.
  - **Quote:** Not applicable.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not indicate any changes to the ground truth of BigCloneBench.
  - **Quote:** Not applicable.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper uses BigCloneBench as part of BigCloneEval without mentioning a subset from previous work.
  - **Quote:** Not applicable.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** Yes.
  - **Explanation:** The paper mentions manual validation of detected clone pairs.
  - **Quote:** "For each tool, we randomly selected 400 of the detected clone pairs from BigCloneBench and validated them manually"【4:15†source】.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not applicable.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could affect the validity of the evaluation results if these pairs were included in the evaluation.
  - **Impact:** This could impact the methodology and conclusions regarding NIL's accuracy and precision if the WT3/T4 subset was used without filtering. The generalizability of the results might be compromised if the evaluation relied on incorrect ground truth data. However, since the paper does not specify the use of WT3/T4, the exact impact is uncertain.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 200, No, Yes, Yes, No, Not specified, No, Not specified, No, No, Yes, No, Potentially
```

**Note:**  
- **E:** The paper does not specify which version of BigCloneBench is used.
- **G:** The paper does not specify whether the WT3/T4 subset was excluded.
- **L:** The finding that 93.35% of WT3/T4 pairs are not clones could potentially affect the paper's claims if these pairs were included in the evaluation. However, the exact impact is uncertain due to the lack of specific information on the use of WT3/T4.
