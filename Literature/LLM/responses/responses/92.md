# Analysis of Paper 92

### Task 1: Extract Key Metadata

- **Title:** NiCad+: Speeding the Detecting Process of NiCad
- **Authors:** Chenhui Feng, Tao Wang, Jinze Liu, Yang Zhang, Kele Xu, and Yijie Wang
- **Publication Year:** 2020【4:19†source】.

### Task 2: Summarize the Paper

The paper titled "NiCad+: Speeding the Detecting Process of NiCad" focuses on enhancing the efficiency of the NiCad tool, which is used for code clone detection. The authors identify that while NiCad has high precision and recall, it is not efficient for large-scale code clone detection due to its slow processing speed. To address this, they propose NiCad+, an improved version that significantly reduces the time-cost of detection by optimizing the matching phase without compromising accuracy. The study uses BigCloneBench as a benchmark to evaluate the performance improvements, demonstrating that NiCad+ achieves the same precision and recall as the original NiCad but with a reduced time-cost【4:19†source】.

### Task 3: Extract Dataset Usage

The paper uses BigCloneBench as a benchmark for evaluating the performance of the NiCad+ tool. It also mentions the use of BigCloneEval, a benchmarking tool that includes the IJaDataset, which contains code clones information of 25,000 Java language projects【4:11†source】【4:18†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is not a systematic literature review or a survey; it is a research study focused on improving a specific tool for code clone detection.
  - **Quote:** "This paper summarized code clone detection tools and techniques in four categories at present and introduced one detection tool, NiCad, with high recall and precision"【4:19†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes.
  - **Explanation:** The paper presents an improved version of an existing tool, NiCad, called NiCad+.
  - **Quote:** "Therefore, we speeded the detection process of NiCad, and named the improved tool NiCad+"【4:19†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as a benchmark for evaluating the performance of NiCad+.
  - **Quote:** "In order to evaluate the code clone detection tools, we take BigCloneBench as our benchmark"【4:18†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper does not mention using BigCloneBench for training a machine learning approach; it is used for evaluation purposes.
  - **Quote:** Not applicable.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Not explicitly mentioned.
  - **Explanation:** The paper does not specify which version of BigCloneBench is used.
  - **Quote:** Not applicable.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** No.
  - **Explanation:** The paper does not mention filtering or modifying the ground truth of BigCloneBench.
  - **Quote:** Not applicable.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not explicitly mentioned.
  - **Explanation:** The paper does not provide details on whether the WT3/T4 subset was excluded or included.
  - **Quote:** Not applicable.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes, extensions, or enrichment to the ground truth.
  - **Quote:** Not applicable.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper uses the IJaDataset, which is part of BigCloneEval, a tool developed in previous work.
  - **Quote:** "BigCloneEval includes an extremely large-scale dataset IJaDataset"【4:11†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any validation or manual investigation of BigCloneBench’s ground truth.
  - **Quote:** Not applicable.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not applicable.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** The recent finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the evaluation results if these pairs were included in the benchmark used for testing NiCad+.
  - **Impact on Methodology, Conclusions, or Generalizability:** If the WT3/T4 subset was included in the evaluation, the precision and recall metrics reported for NiCad+ might be inflated, affecting the generalizability of the results. The methodology would need to be reassessed to ensure that the evaluation accurately reflects the tool's performance on true clone pairs.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 92, No, Yes, Yes, No, Not specified, No, Not specified, No, Yes, No, No, Potentially
```

**Note:**  
- **E:** The paper does not specify which version of BigCloneBench is used.
- **G:** The paper does not provide details on whether the WT3/T4 subset was excluded or included.
- **L:** The recent finding about WT3/T4 pairs potentially impacts the validity of the evaluation if these pairs were included.
