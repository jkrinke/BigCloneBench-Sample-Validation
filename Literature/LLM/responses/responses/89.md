# Analysis of Paper 89

### Task 1: Extract Key Metadata

- **Title:** Graph-of-Code: Semantic Clone Detection Using Graph Fingerprints
- **Authors:** Essa A. Alhazami and Abdullah M. Sheneamer
- **Publication Year:** 2023【4:0†source】

### Task 2: Summarize the Paper

The paper titled "Graph-of-Code: Semantic Clone Detection Using Graph Fingerprints" by Essa A. Alhazami and Abdullah M. Sheneamer introduces a novel approach to code clone detection that leverages graph-based representations of code, termed Graph-of-Code (GoC). The methodology focuses on structural properties of code, avoiding exposure of code contents, which addresses privacy concerns and enhances scalability. The study employs machine learning techniques to generate "Graph Fingerprints" that capture topological features of code graphs. The experimental results demonstrate that the GoC approach significantly improves clone detection performance, achieving high precision, recall, and F1-scores. The paper concludes that GoC is effective in detecting both syntactic and semantic clones, offering a scalable solution for large datasets【4:0†source】【4:6†source】.

### Task 3: Extract Dataset Usage

The paper evaluates its approach using the BigCloneBench dataset, which is a large inter-project Java repository containing over 7 million true clone pairs and 260 thousand false clone pairs. The dataset is used to assess the performance of the proposed clone detection method【4:2†source】【4:15†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature systematically.
  - **Quote:** "We have presented a new and novel methodology for code clone detection where codes are represented in graphs."【4:10†source】

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces the Graph-of-Code (GoC) concept for clone detection.
  - **Quote:** "We built a model to detect code clones by augmenting features generated from a Graph-of-Code concept."【4:6†source】

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper evaluates its approach using the BigCloneBench dataset.
  - **Quote:** "We evaluate our approach on the BigCloneBench dataset."【4:15†source】

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The dataset is used to train and test the machine learning models.
  - **Quote:** "Our work contains training and testing phases. Both phases extract features from the GoC to detect clones."【4:16†source】

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The dataset includes 44 target functionalities, which aligns with the new version.
  - **Quote:** "This benchmark was built by mining BigCloneBench for functions from 44 target functionalities."【4:15†source】

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** No specific filtering or modification is mentioned.
  - **Explanation:** The paper does not detail any filtering or modification of the dataset.
  - **Quote:** Not explicitly mentioned in the provided excerpts.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** No exclusion mentioned.
  - **Explanation:** The paper does not mention excluding any specific subsets.
  - **Quote:** Not explicitly mentioned in the provided excerpts.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper uses the dataset as is for evaluation.
  - **Quote:** Not explicitly mentioned in the provided excerpts.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper uses the full dataset for evaluation.
  - **Quote:** Not explicitly mentioned in the provided excerpts.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of manual validation or investigation of the dataset.
  - **Quote:** Not explicitly mentioned in the provided excerpts.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not explicitly mentioned in the provided excerpts.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially, yes.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the paper's results, especially if these pairs were used in the evaluation.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology might be affected if the WT3/T4 pairs were included without verification, leading to potential inaccuracies in clone detection performance metrics. The conclusions regarding the effectiveness of the GoC approach might be overstated if based on flawed ground truth data. The generalizability of the results could be compromised if the dataset's integrity is questioned.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 89, No, Yes, Yes, Yes, New, Not specified, Not specified, No, No, No, No, Potentially
```

**Note:**  
- For questions F and G, the paper does not specify any filtering or exclusion of subsets, hence "Not specified" is used.
- Question L is marked as "Potentially" because the recent finding about WT3/T4 pairs could impact the paper's claims if these pairs were used without verification.
