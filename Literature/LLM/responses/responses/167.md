# Analysis of Paper 167

### Task 1: Extract Key Metadata

- **Title:** Fine-Grained Code Clone Detection with Block-Based Splitting of Abstract Syntax Tree
- **Authors:** Tiancheng Hu, Zijing Xu, Yilin Fang, Yueming Wu, Bin Yuan, Deqing Zou, and Hai Jin
- **Publication Year:** 2023【4:7†source】.

### Task 2: Summarize the Paper

The paper introduces Tamer, a novel tree-based code clone detector designed to improve the detection of syntactic code clones by transforming complex abstract syntax trees (AST) into simpler subtrees. The methodology involves splitting ASTs into subtrees to enhance detection efficiency and enable fine-grained analysis of code clones. The study evaluates Tamer using the BigCloneBench dataset, demonstrating superior performance and scalability compared to ten state-of-the-art clone detectors. The authors conclude that Tamer not only excels in detection performance but also provides detailed similarity reports for code blocks, aiding in security analysis【4:5†source】【4:9†source】.

### Task 3: Extract Dataset Usage

The paper uses the BigCloneBench dataset for evaluation, which consists of more than 8 million labeled clone pairs【4:8†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature.
  - **Quote:** "In this paper, we design Tamer, a scalable and fine-grained tree-based syntactic code clone detector"【4:7†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces Tamer, a new clone detection tool.
  - **Quote:** "In this paper, we design Tamer, a scalable and fine-grained tree-based syntactic code clone detector"【4:7†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper evaluates Tamer using the BigCloneBench dataset.
  - **Quote:** "To examine the detection performance and scalability of Tamer, we evaluate it on a widely used dataset BigCloneBench"【4:7†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The paper does not mention using BigCloneBench for training a machine learning model.
  - **Quote:** Not applicable.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** New version.
  - **Explanation:** The dataset consists of more than 8 million labeled clone pairs, indicating the new version.
  - **Quote:** "The BCB dataset consists of more than 8,000,000 labeled clone pairs"【4:8†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, filtered.
  - **Explanation:** The paper mentions ignoring Type-4 clones and focusing on other types.
  - **Quote:** "As aforementioned, since T4 code clones are semantic clones and are difficult to be distinguished, we ignore them and pay more attention to the other types"【4:8†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Yes, excluded.
  - **Explanation:** The paper explicitly states ignoring Type-4 clones.
  - **Quote:** "As aforementioned, since T4 code clones are semantic clones and are difficult to be distinguished, we ignore them"【4:8†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes to the ground truth beyond filtering.
  - **Quote:** Not applicable.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** No.
  - **Explanation:** The paper does not mention using a subset from previous work.
  - **Quote:** Not applicable.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of manual validation of the dataset.
  - **Quote:** Not applicable.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** Not applicable.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Yes.
  - **Explanation:** The exclusion of WT3/T4 clones, which are now known to be largely incorrect, suggests that the paper's results are not affected by this specific issue. However, the reliance on BigCloneBench without further validation could still impact the generalizability of the findings.
  - **Quote:** "As aforementioned, since T4 code clones are semantic clones and are difficult to be distinguished, we ignore them"【4:8†source】.

The recent finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones highlights the importance of validating datasets used for evaluation. While the paper's exclusion of these pairs mitigates direct impact, the overall trust in BigCloneBench's ground truth could affect the perceived reliability of the study's conclusions. This underscores the need for careful dataset validation in future research.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 167, No, Yes, Yes, No, New, Yes, Yes, No, No, No, No, Yes
```

**Note:**  
- **F:** The paper filtered out Type-4 clones, focusing on other types.
- **G:** The WT3/T4 subset was excluded from evaluation.
- **L:** The exclusion of WT3/T4 clones mitigates direct impact, but reliance on BigCloneBench without further validation could affect generalizability.
