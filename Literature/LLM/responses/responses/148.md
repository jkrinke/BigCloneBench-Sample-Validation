# Analysis of Paper 148

### Task 1: Extract Key Metadata

- **Title:** Milo: Attacking Deep Pre-trained Model for Programming Languages Tasks with Anti-analysis Code Obfuscation
- **Authors:** Leo Song, Steven H.H. Ding
- **Publication Year:** 2023【4:5†source】

### Task 2: Summarize the Paper

The paper introduces Milo, a multi-programming-language obfuscation tool designed to test the robustness and generalizability of pre-trained BERT models in programming language processing tasks. The study evaluates the impact of various obfuscation techniques on tasks such as code clone detection, code search, and code translation using models like CodeBERT and GraphCodeBERT. The findings reveal that these models heavily rely on literal representations, such as names and strings, and are susceptible to obfuscation, suggesting a need for more structured information during training to enhance model robustness【4:5†source】【4:6†source】.

### Task 3: Extract Dataset Usage

The paper uses the BigCloneBench dataset for evaluating code clone detection tasks【4:2†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper is an empirical study focusing on the impact of code obfuscation on pre-trained BERT models.
  - **Quote:** "We introduce a new code obfuscation tool, a Multi-programming-language Obfuscator (Milo), for programming language processing tasks"【4:5†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Evaluate existing approaches.
  - **Explanation:** The paper evaluates the performance of existing models like CodeBERT and GraphCodeBERT on obfuscated datasets.
  - **Quote:** "We have performed extensive experiments across several pre-trained models, BERT, CodeBERT, and GraphCodeBERT"【4:5†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** The paper uses BigCloneBench for evaluating the code clone detection task.
  - **Quote:** "Experiments are conducted on the BigCloneBench dataset"【4:2†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** No.
  - **Explanation:** The dataset is used for evaluation, not for training.
  - **Quote:** "The fine-tuning process is similar to code search where only the test set is obfuscated"【4:2†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Not specified.
  - **Explanation:** The paper does not specify which version of BigCloneBench is used.
  - **Quote:** "Experiments are conducted on the BigCloneBench dataset"【4:2†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention any filtering or modification of the BigCloneBench dataset.
  - **Quote:** "Experiments are conducted on the BigCloneBench dataset"【4:2†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not specified.
  - **Explanation:** The paper does not provide details on the exclusion or inclusion of the WT3/T4 subset.
  - **Quote:** "Experiments are conducted on the BigCloneBench dataset"【4:2†source】.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes, extensions, or enrichment to the ground truth.
  - **Quote:** "Experiments are conducted on the BigCloneBench dataset"【4:2†source】.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Not specified.
  - **Explanation:** The paper does not mention using a subset created by previous work.
  - **Quote:** "Experiments are conducted on the BigCloneBench dataset"【4:2†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** The paper does not mention any validation or manual investigation of BigCloneBench’s ground truth.
  - **Quote:** "Experiments are conducted on the BigCloneBench dataset"【4:2†source】.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** The references do not include "BigCloneBench Considered Harmful for Machine Learning"【4:9†source】.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially.
  - **Explanation:** The finding that 93.35% of WT3/T4 pairs in BigCloneBench are not clones could impact the validity of the evaluation results if these subsets were used. However, the paper does not specify the use of WT3/T4, so the direct impact is unclear.
  - **Impact on Methodology, Conclusions, or Generalizability:** If WT3/T4 was used, the methodology's reliability could be questioned, potentially affecting the conclusions drawn about the robustness of the models against obfuscation. The generalizability of the results might be limited if the dataset's integrity is compromised by incorrect clone pairs.

# Summary

```plaintext
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 148, No, Evaluate existing approaches, Yes, No, Not specified, Not specified, Not specified, No, Not specified, No, No, Potentially
```

**Note:**  
- The paper does not specify which version of BigCloneBench is used, nor does it provide details on filtering or the use of the WT3/T4 subset. 
- The potential impact of the new findings regarding WT3/T4 pairs is noted as "Potentially" because the paper does not specify the use of these subsets, leaving the direct impact unclear.
