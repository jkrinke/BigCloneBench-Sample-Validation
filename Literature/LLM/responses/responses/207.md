# Analysis of Paper 207

### Task 1: Extract Key Metadata

- **Title:** Compressing Pre-trained Models of Code into 3 MB
- **Authors:** Jieke Shi, Zhou Yang, Bowen Xu, Hong Jin Kang, and David Lo
- **Publication Year:** 2022【4:5†source】.

### Task 2: Summarize the Paper

The paper proposes a novel approach called Compressor, which aims to compress large pre-trained models of code into significantly smaller models with minimal performance loss. The methodology involves using a genetic algorithm to simplify the model architecture and knowledge distillation to train the smaller model. The study evaluates Compressor using two state-of-the-art pre-trained models, CodeBERT and GraphCodeBERT, on tasks such as vulnerability prediction and clone detection. The results demonstrate that Compressor can reduce model size to 3 MB, maintaining over 96% of the original model's accuracy while significantly improving inference speed. The paper concludes that Compressor is effective in compressing pre-trained models, making them more suitable for deployment on resource-constrained devices【4:5†source】【4:10†source】.

### Task 3: Extract Dataset Usage

The paper uses two datasets for evaluation: Devign for vulnerability prediction and BigCloneBench for clone detection【4:2†source】【4:7†source】.

### Task 4: Analyze BigCloneBench Usage

- **Q A:** Is the paper a systematic literature review (SLR) or a survey?
  - **A:** No.
  - **Explanation:** The paper presents a novel approach rather than reviewing existing literature.
  - **Quote:** "This paper proposes Compressor, a novel approach that can compress the pre-trained models of code into tiny models sacrificing only negligible degradation in model accuracy"【4:10†source】.

- **Q B:** Does the paper present a novel clone detection or clone search approach or evaluate existing approaches?
  - **A:** Yes, it presents a novel approach.
  - **Explanation:** The paper introduces Compressor, a new method for compressing models.
  - **Quote:** "We propose Compressor, a novel compression method via genetic algorithm (GA)-guided model simplification and knowledge distillation"【4:0†source】.

- **Q C:** Does the paper use BigCloneBench for evaluation?
  - **A:** Yes.
  - **Explanation:** BigCloneBench is used as a benchmark for evaluating clone detection.
  - **Quote:** "BigCloneBench is a broadly-used benchmark for clone detection"【4:2†source】.

- **Q D:** Is BigCloneBench used as ground truth for training a machine learning approach?
  - **A:** Yes.
  - **Explanation:** The dataset is used to train and evaluate the compressed models.
  - **Quote:** "Following the settings of prior works, we randomly select 90,102 examples for training and 4,000 for validation and testing"【4:2†source】.

- **Q E:** Which version of BigCloneBench (old/new) has been used?
  - **A:** Old version.
  - **Explanation:** The paper mentions "more than 6,000,000 pairs of cloned Java methods," which corresponds to the old version.
  - **Quote:** "It contains more than 6,000,000 pairs of cloned Java methods"【4:2†source】.

- **Q F:** Has the ground truth of BigCloneBench been filtered/modified? If so, what is the size of the subset used?
  - **A:** Yes, it has been filtered.
  - **Explanation:** A subset of 90,102 examples is used for training.
  - **Quote:** "We randomly select 90,102 examples for training and 4,000 for validation and testing"【4:2†source】.

- **Q G:** Has the WT3/T4 subset been excluded from evaluation? If filtered, was WT3/T4 part of the subset?
  - **A:** Not explicitly mentioned.
  - **Explanation:** The paper does not specify whether WT3/T4 was included or excluded.
  - **Quote:** No specific quote available.

- **Q H:** Ignoring filtering, has the ground truth otherwise been changed, extended, or enriched?
  - **A:** No.
  - **Explanation:** The paper does not mention any changes to the ground truth beyond filtering.
  - **Quote:** No specific quote available.

- **Q I:** Has the paper used a subset created by previous work?
  - **A:** Yes.
  - **Explanation:** The paper follows the settings of prior works for dataset selection.
  - **Quote:** "Following the settings of prior works"【4:2†source】.

- **Q J:** Has the paper validated or manually investigated BigCloneBench’s ground truth?
  - **A:** No.
  - **Explanation:** There is no mention of manual validation or investigation of the dataset.
  - **Quote:** No specific quote available.

- **Q K:** Does the paper cite "BigCloneBench Considered Harmful for Machine Learning"?
  - **A:** No.
  - **Explanation:** The paper does not cite this work.
  - **Quote:** No specific quote available.

### Task 5: Critical Analysis – Impact of New Findings

- **Q L:** Does this finding weaken or invalidate any claims in the paper?
  - **A:** Potentially, yes.
  - **Explanation:** If 93.35% of WT3/T4 pairs are not clones, this could significantly affect the validity of the clone detection results, especially if WT3/T4 was part of the evaluation subset.
  - **Impact on Methodology, Conclusions, or Generalizability:** The methodology might need to be revisited to ensure the accuracy of clone detection results. The conclusions regarding the effectiveness of Compressor in clone detection could be less reliable if based on flawed ground truth. The generalizability of the results might be compromised if the dataset's integrity is questioned.

# Summary

```
Question, A, B, C, D, E, F, G, H, I, J, K, L
Paper 207, No, Yes, Yes, Yes, Old, Yes, Not specified, No, Yes, No, No, Potentially
```

**Note:**  
- For question G, the paper does not specify whether the WT3/T4 subset was included or excluded.
- For question L, the finding that 93.35% of WT3/T4 pairs are not clones could potentially weaken the paper's claims if these pairs were part of the evaluation subset.
